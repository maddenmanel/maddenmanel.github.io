<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-01-23T22:28:15+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Madden’s Blog</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><author><name>Madden Zhang</name></author><entry><title type="html">Devops CI/CD Jenkins</title><link href="http://localhost:4000/blog/devops-cicd-jenkins/" rel="alternate" type="text/html" title="Devops CI/CD Jenkins" /><published>2025-01-23T00:00:00+08:00</published><updated>2025-01-23T00:00:00+08:00</updated><id>http://localhost:4000/blog/devops-cicd-jenkins</id><content type="html" xml:base="http://localhost:4000/blog/devops-cicd-jenkins/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Jenkins is a popular open-source automation server that facilitates continuous integration and continuous delivery (CI/CD). It helps automate the building, testing, and deployment of applications. This guide provides detailed steps to install Jenkins on <strong>macOS</strong> using <strong>Docker</strong>, configure a basic pipeline, and introduce approval processes for SQL script execution and release deployment.</p>

<p>Using Docker simplifies the installation process and ensures that Jenkins is isolated in a container, avoiding dependency conflicts with the host system. After installation, we will configure Jenkins for building, testing, and deploying applications while introducing a simple approval process.</p>

<hr />

<h2 id="prerequisites">Prerequisites</h2>

<p>Before proceeding, ensure you have the following:</p>

<ul>
  <li><strong>macOS</strong> machine with an internet connection.</li>
  <li><strong>Docker</strong> installed on your system. If not, download it from <a href="https://www.docker.com/products/docker-desktop">Docker</a> and install it.</li>
  <li><strong>Jenkins user credentials</strong> for logging into the Jenkins UI.</li>
</ul>

<hr />

<h2 id="step-1-install-docker">Step 1: Install Docker</h2>

<p>First, ensure Docker is installed on your <strong>macOS</strong> system. If you haven’t done it yet, download Docker Desktop for macOS from the <a href="https://www.docker.com/products/docker-desktop">official website</a>. Once downloaded, follow the installation steps.</p>

<p>To verify the installation, run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nt">--version</span>
</code></pre></div></div>

<p>This should return the Docker version installed.</p>

<hr />

<h2 id="step-2-pull-the-jenkins-docker-image">Step 2: Pull the Jenkins Docker Image</h2>

<p>Now that Docker is installed, we can pull the official Jenkins image. Open your terminal and run the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull jenkins/jenkins:lts
</code></pre></div></div>

<p>This will pull the <strong>Long-Term Support (LTS)</strong> version of Jenkins, which is stable and recommended for production environments.</p>

<hr />

<h2 id="step-3-run-jenkins-using-docker">Step 3: Run Jenkins Using Docker</h2>

<p>Once the image is downloaded, you can run Jenkins in a Docker container. Execute the following command to run Jenkins:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:8080 <span class="nt">-p</span> 50000:50000 <span class="nt">--name</span> jenkins jenkins/jenkins:lts
</code></pre></div></div>

<h3 id="explanation">Explanation:</h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">-d</code>: Run the container in detached mode.</li>
  <li><code class="language-plaintext highlighter-rouge">-p 8080:8080</code>: Map port <code class="language-plaintext highlighter-rouge">8080</code> on the container to port <code class="language-plaintext highlighter-rouge">8080</code> on your host, which allows you to access Jenkins UI at <code class="language-plaintext highlighter-rouge">http://localhost:8080</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">-p 50000:50000</code>: Expose the port <code class="language-plaintext highlighter-rouge">50000</code> for communication between Jenkins and its agents.</li>
  <li><code class="language-plaintext highlighter-rouge">--name jenkins</code>: Name the container <code class="language-plaintext highlighter-rouge">jenkins</code> for easy reference.</li>
</ul>

<hr />

<h2 id="step-4-access-jenkins-web-interface">Step 4: Access Jenkins Web Interface</h2>

<p>To access Jenkins, open your web browser and navigate to:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>http://localhost:8080
</code></pre></div></div>

<p>On your first visit, Jenkins will ask for an <strong>unlock key</strong>. To retrieve it, execute the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nb">exec</span> <span class="nt">-it</span> jenkins <span class="nb">cat</span> /var/jenkins_home/secrets/initialAdminPassword
</code></pre></div></div>

<p>Copy the output (the password), and paste it into the Jenkins unlock screen to proceed with the initial setup.</p>

<hr />

<h2 id="step-5-set-up-jenkins">Step 5: Set Up Jenkins</h2>

<p>Once Jenkins is unlocked, follow the setup wizard:</p>

<ol>
  <li><strong>Install suggested plugins</strong>: Jenkins will suggest a set of commonly used plugins. Click on “Install suggested plugins.”</li>
  <li><strong>Create an admin user</strong>: After plugins are installed, create a user with admin privileges by following the prompts. This is your primary user for accessing Jenkins.</li>
  <li><strong>Jenkins Setup Complete</strong>: After creating the admin user, Jenkins will show a “Setup is Complete” message.</li>
</ol>

<hr />

<h2 id="step-6-configure-jenkins-pipeline-with-sql-and-release-approval">Step 6: Configure Jenkins Pipeline with SQL and Release Approval</h2>

<p>Jenkins allows you to automate tasks through <strong>Pipelines</strong>, which define your build, test, and deployment workflows. To get started, we’ll configure a simple pipeline and introduce an <strong>approval process</strong> before executing SQL scripts and releasing deployments.</p>

<h3 id="a-install-required-plugins">a) Install Required Plugins</h3>

<p>To enable pipeline support and approval steps, you need the following plugins:</p>

<ol>
  <li><strong>Pipeline</strong>: For creating Jenkins pipelines.</li>
  <li><strong>Input Step Plugin</strong>: To introduce manual approval in the pipeline.</li>
</ol>

<p>To install these:</p>

<ol>
  <li>Go to <code class="language-plaintext highlighter-rouge">Manage Jenkins</code> &gt; <code class="language-plaintext highlighter-rouge">Manage Plugins</code>.</li>
  <li>Under the <strong>Available</strong> tab, search and install the <strong>Pipeline</strong> and <strong>Input Step Plugin</strong>.</li>
</ol>

<h3 id="b-create-a-new-pipeline">b) Create a New Pipeline</h3>

<ol>
  <li>On the Jenkins dashboard, click on <strong>New Item</strong>.</li>
  <li>Enter a name for your project (e.g., “MyFirstPipeline”).</li>
  <li>Choose <strong>Pipeline</strong> and click <strong>OK</strong>.</li>
  <li>In the configuration screen, scroll down to the <strong>Pipeline</strong> section and enter the following script:</li>
</ol>

<div class="language-groovy highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>

    <span class="n">environment</span> <span class="o">{</span>
        <span class="c1">// 这里可以设置一些全局变量或常用参数，如数据库连接等</span>
        <span class="n">DB_HOST</span> <span class="o">=</span> <span class="s1">'your_db_host'</span>
        <span class="n">DB_USER</span> <span class="o">=</span> <span class="s1">'your_db_user'</span>
        <span class="n">DB_PASS</span> <span class="o">=</span> <span class="s1">'your_db_password'</span>
    <span class="o">}</span>

    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="c1">// 检出代码库，假设你使用Git</span>
                <span class="n">checkout</span> <span class="n">scm</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'SQL Approval'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="c1">// 在SQL审批阶段进行人工审批，审批人员可以填写SQL审批意见</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="kt">def</span> <span class="n">approval</span> <span class="o">=</span> <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'SQL脚本审批'</span><span class="o">,</span> 
                                          <span class="nl">parameters:</span> <span class="o">[</span>
                                              <span class="n">string</span><span class="o">(</span><span class="nl">defaultValue:</span> <span class="s1">''</span><span class="o">,</span> <span class="nl">description:</span> <span class="s1">'请输入SQL审批意见'</span><span class="o">,</span> <span class="nl">name:</span> <span class="s1">'sql_approval_comments'</span><span class="o">)</span>
                                          <span class="o">]</span>
                    <span class="c1">// 将审批意见存储或使用</span>
                    <span class="n">echo</span> <span class="s2">"SQL审批意见: ${approval['sql_approval_comments']}"</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'Run SQL Scripts'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="c1">// 在SQL审批通过后执行SQL脚本</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">echo</span> <span class="s1">'执行SQL脚本...'</span>
                    <span class="c1">// 这里假设你用sh步骤来执行SQL脚本，也可以使用数据库相关插件</span>
                    <span class="n">sh</span> <span class="s1">'''
                    mysql -h ${DB_HOST} -u ${DB_USER} -p${DB_PASS} -e "source ./your_sql_script.sql"
                    '''</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'Release Approval'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="c1">// 在上线前进行审批，审批人可以填写上线内容</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="kt">def</span> <span class="n">releaseApproval</span> <span class="o">=</span> <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'是否批准上线？'</span><span class="o">,</span>
                                                 <span class="nl">parameters:</span> <span class="o">[</span>
                                                     <span class="n">string</span><span class="o">(</span><span class="nl">defaultValue:</span> <span class="s1">''</span><span class="o">,</span> <span class="nl">description:</span> <span class="s1">'请输入上线内容'</span><span class="o">,</span> <span class="nl">name:</span> <span class="s1">'release_notes'</span><span class="o">),</span>
                                                     <span class="n">string</span><span class="o">(</span><span class="nl">defaultValue:</span> <span class="s1">''</span><span class="o">,</span> <span class="nl">description:</span> <span class="s1">'请输入上线审批意见'</span><span class="o">,</span> <span class="nl">name:</span> <span class="s1">'release_approval_comments'</span><span class="o">)</span>
                                                 <span class="o">]</span>
                    <span class="c1">// 获取上线内容和审批意见</span>
                    <span class="n">echo</span> <span class="s2">"上线内容: ${releaseApproval['release_notes']}"</span>
                    <span class="n">echo</span> <span class="s2">"上线审批意见: ${releaseApproval['release_approval_comments']}"</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="c1">// 上线操作，假设部署应用</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">echo</span> <span class="s1">'执行部署操作...'</span>
                    <span class="n">sh</span> <span class="s1">'''
                    ./deploy.sh  # 替换为实际的部署脚本或命令
                    '''</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>

    <span class="n">post</span> <span class="o">{</span>
        <span class="n">always</span> <span class="o">{</span>
            <span class="c1">// 这里可以定义清理工作或通知等</span>
            <span class="n">echo</span> <span class="s1">'Pipeline 执行完毕'</span>
        <span class="o">}</span>

        <span class="n">success</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s1">'Pipeline 执行成功'</span>
        <span class="o">}</span>

        <span class="n">failure</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s1">'Pipeline 执行失败'</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<h3 id="c-save-and-run-the-pipeline">c) Save and Run the Pipeline</h3>

<ul>
  <li>After entering the pipeline script, click <strong>Save</strong>.</li>
  <li>Trigger the pipeline by clicking <strong>Build Now</strong>.</li>
</ul>

<p>The pipeline will:</p>
<ol>
  <li><strong>Checkout</strong> the code from your version control system (assuming it’s linked).</li>
  <li><strong>SQL Approval</strong>: Wait for manual approval and SQL comments before executing SQL scripts.</li>
  <li><strong>Run SQL Scripts</strong>: Execute SQL scripts only after SQL approval.</li>
  <li><strong>Release Approval</strong>: Wait for manual approval of the release, where the release notes and approval comments are entered.</li>
  <li><strong>Deploy</strong>: Once all approvals are granted, the deployment will proceed.</li>
</ol>

<hr />

<h2 id="step-7-monitor-jenkins-logs-and-jobs">Step 7: Monitor Jenkins Logs and Jobs</h2>

<p>To monitor Jenkins logs and ensure the server is running smoothly, use the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker logs <span class="nt">-f</span> jenkins
</code></pre></div></div>

<p>This will display Jenkins logs in real-time. To view the build job logs, go to the <strong>Build History</strong> section in your Jenkins project page.</p>

<hr />

<h2 id="step-8-automating-jenkins-restart-optional">Step 8: Automating Jenkins Restart (Optional)</h2>

<p>To ensure that Jenkins restarts automatically after a system reboot, you can set up Docker’s restart policy. Stop the container and run the following command to restart it automatically on failure or reboot:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker update <span class="nt">--restart</span> unless-stopped jenkins
</code></pre></div></div>

<hr />

<h2 id="step-9-configure-backups-optional">Step 9: Configure Backups (Optional)</h2>

<p>It’s important to regularly back up your Jenkins data. To back up your Jenkins instance and its configuration, follow these steps:</p>

<ol>
  <li>
    <p><strong>Stop the Jenkins container</strong>:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker stop jenkins
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Create a backup of Jenkins data</strong>:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nb">cp </span>jenkins:/var/jenkins_home /path/to/backup/folder
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Restart the Jenkins container</strong>:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker start jenkins
</code></pre></div>    </div>
  </li>
</ol>

<hr />

<h2 id="conclusion">Conclusion</h2>

<p>By following this guide, you have successfully installed Jenkins on your <strong>macOS</strong> using Docker, set up a basic <strong>CI/CD pipeline</strong> with SQL and release approval processes. You can now automate your builds, tests, and deployments, and track the approval steps</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="devOps" /><category term="jenkins" /><category term="CI/CD" /><summary type="html"><![CDATA[Introduction Jenkins is a popular open-source automation server that facilitates continuous integration and continuous delivery (CI/CD). It helps automate the building, testing, and deployment of applications. This guide provides detailed steps to install Jenkins on macOS using Docker, configure a basic pipeline, and introduce approval processes for SQL script execution and release deployment. Using Docker simplifies the installation process and ensures that Jenkins is isolated in a container, avoiding dependency conflicts with the host system. After installation, we will configure Jenkins for building, testing, and deploying applications while introducing a simple approval process. Prerequisites Before proceeding, ensure you have the following: macOS machine with an internet connection. Docker installed on your system. If not, download it from Docker and install it. Jenkins user credentials for logging into the Jenkins UI. Step 1: Install Docker First, ensure Docker is installed on your macOS system. If you haven’t done it yet, download Docker Desktop for macOS from the official website. Once downloaded, follow the installation steps. To verify the installation, run: docker --version This should return the Docker version installed. Step 2: Pull the Jenkins Docker Image Now that Docker is installed, we can pull the official Jenkins image. Open your terminal and run the following command: docker pull jenkins/jenkins:lts This will pull the Long-Term Support (LTS) version of Jenkins, which is stable and recommended for production environments. Step 3: Run Jenkins Using Docker Once the image is downloaded, you can run Jenkins in a Docker container. Execute the following command to run Jenkins: docker run -d -p 8080:8080 -p 50000:50000 --name jenkins jenkins/jenkins:lts Explanation: -d: Run the container in detached mode. -p 8080:8080: Map port 8080 on the container to port 8080 on your host, which allows you to access Jenkins UI at http://localhost:8080. -p 50000:50000: Expose the port 50000 for communication between Jenkins and its agents. --name jenkins: Name the container jenkins for easy reference. Step 4: Access Jenkins Web Interface To access Jenkins, open your web browser and navigate to: http://localhost:8080 On your first visit, Jenkins will ask for an unlock key. To retrieve it, execute the following command: docker exec -it jenkins cat /var/jenkins_home/secrets/initialAdminPassword Copy the output (the password), and paste it into the Jenkins unlock screen to proceed with the initial setup. Step 5: Set Up Jenkins Once Jenkins is unlocked, follow the setup wizard: Install suggested plugins: Jenkins will suggest a set of commonly used plugins. Click on “Install suggested plugins.” Create an admin user: After plugins are installed, create a user with admin privileges by following the prompts. This is your primary user for accessing Jenkins. Jenkins Setup Complete: After creating the admin user, Jenkins will show a “Setup is Complete” message. Step 6: Configure Jenkins Pipeline with SQL and Release Approval Jenkins allows you to automate tasks through Pipelines, which define your build, test, and deployment workflows. To get started, we’ll configure a simple pipeline and introduce an approval process before executing SQL scripts and releasing deployments. a) Install Required Plugins To enable pipeline support and approval steps, you need the following plugins: Pipeline: For creating Jenkins pipelines. Input Step Plugin: To introduce manual approval in the pipeline. To install these: Go to Manage Jenkins &gt; Manage Plugins. Under the Available tab, search and install the Pipeline and Input Step Plugin. b) Create a New Pipeline On the Jenkins dashboard, click on New Item. Enter a name for your project (e.g., “MyFirstPipeline”). Choose Pipeline and click OK. In the configuration screen, scroll down to the Pipeline section and enter the following script: pipeline { agent any environment { // 这里可以设置一些全局变量或常用参数，如数据库连接等 DB_HOST = 'your_db_host' DB_USER = 'your_db_user' DB_PASS = 'your_db_password' } stages { stage('Checkout') { steps { // 检出代码库，假设你使用Git checkout scm } } stage('SQL Approval') { steps { // 在SQL审批阶段进行人工审批，审批人员可以填写SQL审批意见 script { def approval = input message: 'SQL脚本审批', parameters: [ string(defaultValue: '', description: '请输入SQL审批意见', name: 'sql_approval_comments') ] // 将审批意见存储或使用 echo "SQL审批意见: ${approval['sql_approval_comments']}" } } } stage('Run SQL Scripts') { steps { // 在SQL审批通过后执行SQL脚本 script { echo '执行SQL脚本...' // 这里假设你用sh步骤来执行SQL脚本，也可以使用数据库相关插件 sh ''' mysql -h ${DB_HOST} -u ${DB_USER} -p${DB_PASS} -e "source ./your_sql_script.sql" ''' } } } stage('Release Approval') { steps { // 在上线前进行审批，审批人可以填写上线内容 script { def releaseApproval = input message: '是否批准上线？', parameters: [ string(defaultValue: '', description: '请输入上线内容', name: 'release_notes'), string(defaultValue: '', description: '请输入上线审批意见', name: 'release_approval_comments') ] // 获取上线内容和审批意见 echo "上线内容: ${releaseApproval['release_notes']}" echo "上线审批意见: ${releaseApproval['release_approval_comments']}" } } } stage('Deploy') { steps { // 上线操作，假设部署应用 script { echo '执行部署操作...' sh ''' ./deploy.sh # 替换为实际的部署脚本或命令 ''' } } } } post { always { // 这里可以定义清理工作或通知等 echo 'Pipeline 执行完毕' } success { echo 'Pipeline 执行成功' } failure { echo 'Pipeline 执行失败' } } } c) Save and Run the Pipeline After entering the pipeline script, click Save. Trigger the pipeline by clicking Build Now. The pipeline will: Checkout the code from your version control system (assuming it’s linked). SQL Approval: Wait for manual approval and SQL comments before executing SQL scripts. Run SQL Scripts: Execute SQL scripts only after SQL approval. Release Approval: Wait for manual approval of the release, where the release notes and approval comments are entered. Deploy: Once all approvals are granted, the deployment will proceed. Step 7: Monitor Jenkins Logs and Jobs To monitor Jenkins logs and ensure the server is running smoothly, use the following command: docker logs -f jenkins This will display Jenkins logs in real-time. To view the build job logs, go to the Build History section in your Jenkins project page. Step 8: Automating Jenkins Restart (Optional) To ensure that Jenkins restarts automatically after a system reboot, you can set up Docker’s restart policy. Stop the container and run the following command to restart it automatically on failure or reboot: docker update --restart unless-stopped jenkins Step 9: Configure Backups (Optional) It’s important to regularly back up your Jenkins data. To back up your Jenkins instance and its configuration, follow these steps: Stop the Jenkins container: docker stop jenkins Create a backup of Jenkins data: docker cp jenkins:/var/jenkins_home /path/to/backup/folder Restart the Jenkins container: docker start jenkins Conclusion By following this guide, you have successfully installed Jenkins on your macOS using Docker, set up a basic CI/CD pipeline with SQL and release approval processes. You can now automate your builds, tests, and deployments, and track the approval steps]]></summary></entry><entry><title type="html">DevOps CI/CD GitLab</title><link href="http://localhost:4000/blog/devops-cicd-gitlab/" rel="alternate" type="text/html" title="DevOps CI/CD GitLab" /><published>2025-01-23T00:00:00+08:00</published><updated>2025-01-23T00:00:00+08:00</updated><id>http://localhost:4000/blog/devops-cicd-gitlab</id><content type="html" xml:base="http://localhost:4000/blog/devops-cicd-gitlab/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>GitLab is a powerful DevOps platform that provides a complete CI/CD pipeline for automating the build, test, and deployment of applications. In this guide, we’ll walk you through the steps to install <strong>GitLab</strong> on <strong>macOS</strong> using <strong>Docker</strong> and configure it for CI/CD workflows.</p>

<hr />

<h2 id="prerequisites">Prerequisites</h2>

<p>Before proceeding, ensure you have the following:</p>

<ul>
  <li><strong>macOS</strong> machine with an internet connection.</li>
  <li><strong>Docker</strong> installed on your system. If not, download it from <a href="https://www.docker.com/products/docker-desktop">Docker</a> and install it.</li>
  <li><strong>GitLab user credentials</strong> for accessing the GitLab UI.</li>
</ul>

<hr />

<h2 id="step-1-install-docker">Step 1: Install Docker</h2>

<p>First, ensure Docker is installed on your <strong>macOS</strong> system. If you haven’t done it yet, download Docker Desktop for macOS from the <a href="https://www.docker.com/products/docker-desktop">official website</a>. Once downloaded, follow the installation steps.</p>

<p>To verify the installation, run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nt">--version</span>
</code></pre></div></div>

<p>This should return the Docker version installed.</p>

<hr />

<h2 id="step-2-pull-the-gitlab-docker-image">Step 2: Pull the GitLab Docker Image</h2>

<p>To install <strong>GitLab</strong> using Docker, run the following command to pull the official GitLab Community Edition image:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull gitlab/gitlab-ce:latest
</code></pre></div></div>

<hr />

<h2 id="step-3-run-gitlab-using-docker">Step 3: Run GitLab Using Docker</h2>

<p>Once the image is downloaded, you can run GitLab in a Docker container. Execute the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run <span class="nt">-d</span> <span class="nt">-p</span> 80:80 <span class="nt">-p</span> 443:443 <span class="nt">-p</span> 22:22 <span class="nt">--name</span> gitlab <span class="nt">--restart</span> always <span class="se">\</span>
<span class="nt">-v</span> /your/host/path/to/gitlab/config:/etc/gitlab <span class="se">\</span>
<span class="nt">-v</span> /your/host/path/to/gitlab/data:/var/opt/gitlab <span class="se">\</span>
<span class="nt">-v</span> /your/host/path/to/gitlab/logs:/var/log/gitlab <span class="se">\</span>
gitlab/gitlab-ce:latest
</code></pre></div></div>

<h3 id="explanation">Explanation:</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">-p 80:80 -p 443:443 -p 22:22</code>: Maps the required ports for HTTP, HTTPS, and SSH.</li>
  <li><code class="language-plaintext highlighter-rouge">--name gitlab</code>: Names the container <code class="language-plaintext highlighter-rouge">gitlab</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">--restart always</code>: Ensures GitLab restarts automatically if the container or Docker daemon restarts.</li>
  <li><code class="language-plaintext highlighter-rouge">-v /your/host/path</code>: Mounts host directories to the container for persistent data.</li>
</ul>

<p>Replace <code class="language-plaintext highlighter-rouge">/your/host/path</code> with the actual paths on your machine where GitLab data, logs, and configuration will be stored.</p>

<hr />

<h2 id="step-4-access-gitlab-web-interface">Step 4: Access GitLab Web Interface</h2>

<p>Once GitLab is running, open your web browser and navigate to:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>http://localhost
</code></pre></div></div>

<p>You should see the GitLab setup page. Follow the instructions to set up an admin password and configure your GitLab instance.</p>

<hr />

<h2 id="step-5-configure-gitlab-for-cicd">Step 5: Configure GitLab for CI/CD</h2>

<p>GitLab offers built-in CI/CD features to automate the build, test, and deployment of your code. To configure GitLab CI/CD:</p>

<ol>
  <li><strong>Create a <code class="language-plaintext highlighter-rouge">.gitlab-ci.yml</code> file</strong> in the root of your repository. This file defines the CI/CD pipeline for your project.</li>
</ol>

<p>Example <code class="language-plaintext highlighter-rouge">.gitlab-ci.yml</code> for a simple Node.js application:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">stages</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">build</span>
  <span class="pi">-</span> <span class="s">test</span>
  <span class="pi">-</span> <span class="s">deploy</span>

<span class="na">build</span><span class="pi">:</span>
  <span class="na">stage</span><span class="pi">:</span> <span class="s">build</span>
  <span class="na">script</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">npm install</span>

<span class="na">test</span><span class="pi">:</span>
  <span class="na">stage</span><span class="pi">:</span> <span class="s">test</span>
  <span class="na">script</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">npm test</span>

<span class="na">deploy</span><span class="pi">:</span>
  <span class="na">stage</span><span class="pi">:</span> <span class="s">deploy</span>
  <span class="na">script</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">./deploy.sh</span>
</code></pre></div></div>

<ol>
  <li><strong>Push your repository to GitLab</strong>. GitLab will automatically detect the <code class="language-plaintext highlighter-rouge">.gitlab-ci.yml</code> file and trigger the pipeline based on the defined stages.</li>
</ol>

<hr />

<h2 id="step-6-monitor-gitlab-logs">Step 6: Monitor GitLab Logs</h2>

<p>To monitor the logs of the GitLab container, you can use the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker logs <span class="nt">-f</span> gitlab
</code></pre></div></div>

<p>This will show real-time logs for the GitLab container.</p>

<hr />

<h2 id="step-7-automating-gitlab-restart-optional">Step 7: Automating GitLab Restart (Optional)</h2>

<p>To ensure GitLab restarts automatically after a system reboot, you can set up Docker’s restart policy. Run the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker update <span class="nt">--restart</span> unless-stopped gitlab
</code></pre></div></div>

<hr />

<h2 id="step-8-backup-gitlab-optional">Step 8: Backup GitLab (Optional)</h2>

<p>It’s important to back up your GitLab data regularly. Follow these steps to back it up:</p>

<ol>
  <li>
    <p><strong>Stop GitLab container</strong>:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker stop gitlab
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Backup GitLab data</strong>:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nb">cp </span>gitlab:/var/opt/gitlab /path/to/gitlab/backup/folder
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Restart GitLab container</strong>:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker start gitlab
</code></pre></div>    </div>
  </li>
</ol>

<hr />

<h2 id="conclusion">Conclusion</h2>

<p>By following this guide, you have successfully installed <strong>GitLab</strong> on <strong>macOS</strong> using Docker and set up <strong>CI/CD pipelines</strong> for your projects. GitLab makes it easy to automate your build, test, and deployment processes.</p>

<p>Let me know if you need further assistance!</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="devOps" /><category term="gitlab" /><category term="CI/CD" /><summary type="html"><![CDATA[Introduction GitLab is a powerful DevOps platform that provides a complete CI/CD pipeline for automating the build, test, and deployment of applications. In this guide, we’ll walk you through the steps to install GitLab on macOS using Docker and configure it for CI/CD workflows. Prerequisites Before proceeding, ensure you have the following: macOS machine with an internet connection. Docker installed on your system. If not, download it from Docker and install it. GitLab user credentials for accessing the GitLab UI. Step 1: Install Docker First, ensure Docker is installed on your macOS system. If you haven’t done it yet, download Docker Desktop for macOS from the official website. Once downloaded, follow the installation steps. To verify the installation, run: docker --version This should return the Docker version installed. Step 2: Pull the GitLab Docker Image To install GitLab using Docker, run the following command to pull the official GitLab Community Edition image: docker pull gitlab/gitlab-ce:latest Step 3: Run GitLab Using Docker Once the image is downloaded, you can run GitLab in a Docker container. Execute the following command: docker run -d -p 80:80 -p 443:443 -p 22:22 --name gitlab --restart always \ -v /your/host/path/to/gitlab/config:/etc/gitlab \ -v /your/host/path/to/gitlab/data:/var/opt/gitlab \ -v /your/host/path/to/gitlab/logs:/var/log/gitlab \ gitlab/gitlab-ce:latest Explanation: -p 80:80 -p 443:443 -p 22:22: Maps the required ports for HTTP, HTTPS, and SSH. --name gitlab: Names the container gitlab. --restart always: Ensures GitLab restarts automatically if the container or Docker daemon restarts. -v /your/host/path: Mounts host directories to the container for persistent data. Replace /your/host/path with the actual paths on your machine where GitLab data, logs, and configuration will be stored. Step 4: Access GitLab Web Interface Once GitLab is running, open your web browser and navigate to: http://localhost You should see the GitLab setup page. Follow the instructions to set up an admin password and configure your GitLab instance. Step 5: Configure GitLab for CI/CD GitLab offers built-in CI/CD features to automate the build, test, and deployment of your code. To configure GitLab CI/CD: Create a .gitlab-ci.yml file in the root of your repository. This file defines the CI/CD pipeline for your project. Example .gitlab-ci.yml for a simple Node.js application: stages: - build - test - deploy build: stage: build script: - npm install test: stage: test script: - npm test deploy: stage: deploy script: - ./deploy.sh Push your repository to GitLab. GitLab will automatically detect the .gitlab-ci.yml file and trigger the pipeline based on the defined stages. Step 6: Monitor GitLab Logs To monitor the logs of the GitLab container, you can use the following command: docker logs -f gitlab This will show real-time logs for the GitLab container. Step 7: Automating GitLab Restart (Optional) To ensure GitLab restarts automatically after a system reboot, you can set up Docker’s restart policy. Run the following command: docker update --restart unless-stopped gitlab Step 8: Backup GitLab (Optional) It’s important to back up your GitLab data regularly. Follow these steps to back it up: Stop GitLab container: docker stop gitlab Backup GitLab data: docker cp gitlab:/var/opt/gitlab /path/to/gitlab/backup/folder Restart GitLab container: docker start gitlab Conclusion By following this guide, you have successfully installed GitLab on macOS using Docker and set up CI/CD pipelines for your projects. GitLab makes it easy to automate your build, test, and deployment processes. Let me know if you need further assistance!]]></summary></entry><entry><title type="html">Stability Monitor Promtail</title><link href="http://localhost:4000/blog/stability-monitor-promtail/" rel="alternate" type="text/html" title="Stability Monitor Promtail" /><published>2025-01-14T00:00:00+08:00</published><updated>2025-01-14T00:00:00+08:00</updated><id>http://localhost:4000/blog/stability-monitor-promtail</id><content type="html" xml:base="http://localhost:4000/blog/stability-monitor-promtail/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Promtail is an agent that collects logs from various sources and sends them to Loki for storage and querying. In this section, we will walk through the installation process of Promtail, which includes downloading the necessary files, setting up configuration, and creating a service to ensure Promtail runs continuously as a background service.</p>

<h3 id="step-1-download-promtail">Step 1: Download Promtail</h3>

<p>The first step is to download the Promtail binary from the official GitHub repository. You can find the latest release <a href="https://github.com/grafana/loki/releases">here</a>.</p>

<p>For example, to download version 3.1.2, you can execute the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://github.com/grafana/loki/releases/download/v2.8.0/promtail-linux-amd64.zip
</code></pre></div></div>

<h3 id="step-2-extract-and-move-promtail-to-a-suitable-location">Step 2: Extract and Move Promtail to a Suitable Location</h3>

<p>Once the file is downloaded, extract it and move the binary to a directory included in the system’s <code class="language-plaintext highlighter-rouge">$PATH</code>, such as <code class="language-plaintext highlighter-rouge">/usr/local/bin/</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unzip promtail-linux-amd64.zip
<span class="nb">mv </span>promtail-linux-amd64 /usr/local/bin/promtail
</code></pre></div></div>

<p>Next, grant execute permissions to the Promtail binary to allow it to run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod</span> +x /usr/local/bin/promtail
</code></pre></div></div>

<h3 id="step-3-create-promtail-configuration-file">Step 3: Create Promtail Configuration File</h3>

<p>Promtail requires a configuration file that defines how logs will be collected, where they will be sent, and other parameters. Create the configuration directory and the file as follows:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> /etc/promtail
vim /etc/promtail/promtail-config.yaml
</code></pre></div></div>

<p>Below is a sample configuration file you can use, which specifies the Promtail server settings, position tracking, Loki client configuration, and the log scraping setup.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">server</span><span class="pi">:</span>
  <span class="na">http_listen_port</span><span class="pi">:</span> <span class="m">9080</span>
  <span class="na">grpc_listen_port</span><span class="pi">:</span> <span class="m">0</span>

<span class="na">positions</span><span class="pi">:</span>
  <span class="na">filename</span><span class="pi">:</span> <span class="s">/tmp/positions.yaml</span>

<span class="na">clients</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">url</span><span class="pi">:</span> <span class="s">http://192.168.18.58:3100/loki/api/v1/push</span>
    <span class="na">batchsize</span><span class="pi">:</span> <span class="m">1048576</span>
    <span class="na">batchwait</span><span class="pi">:</span> <span class="s">2s</span>

<span class="na">scrape_configs</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">job_name</span><span class="pi">:</span> <span class="s">your-application-name</span>
    <span class="na">static_configs</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">targets</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s">localhost</span>
        <span class="na">labels</span><span class="pi">:</span>
          <span class="na">job</span><span class="pi">:</span> <span class="s">your-application-name</span>
          <span class="na">__path__</span><span class="pi">:</span> <span class="s">/var/log/your-application-name/*log</span>
</code></pre></div></div>

<h3 id="step-4-create-systemd-service-file">Step 4: Create Systemd Service File</h3>

<p>In order to ensure that Promtail starts automatically during system boot and runs as a background service, we need to create a systemd service file.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim /etc/systemd/system/promtail.service
</code></pre></div></div>

<p>Add the following content to the file:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[Unit]</span>
<span class="py">Description</span><span class="p">=</span><span class="s">Promtail - A log collection agent for Loki</span>
<span class="py">Documentation</span><span class="p">=</span><span class="s">https://grafana.com/docs/loki/latest/clients/promtail/</span>
<span class="py">After</span><span class="p">=</span><span class="s">network.target</span>

<span class="nn">[Service]</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/usr/local/bin/promtail -config.file=/etc/promtail/promtail-config.yaml</span>
<span class="py">Restart</span><span class="p">=</span><span class="s">on-failure</span>
<span class="py">User</span><span class="p">=</span><span class="s">delian</span>
<span class="py">Group</span><span class="p">=</span><span class="s">delian</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</code></pre></div></div>

<h3 id="step-5-start-and-enable-promtail-service">Step 5: Start and Enable Promtail Service</h3>

<p>After creating the systemd service file, reload the systemd manager to register the new service and start it. Additionally, enable it to start automatically at boot time.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>systemctl daemon-reload
systemctl start promtail
systemctl <span class="nb">enable </span>promtail
systemctl status promtail
</code></pre></div></div>

<p>The service will now run in the background, collecting and forwarding logs to Loki according to the specified configuration.</p>

<hr />

<h2 id="conclusion">Conclusion</h2>

<p>In this article, we have outlined the necessary steps to install and configure Promtail. By following these procedures, you will have a fully functional Promtail agent collecting logs and sending them to Loki, ready for real-time log monitoring.</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="monitor" /><category term="stability" /><summary type="html"><![CDATA[Introduction Promtail is an agent that collects logs from various sources and sends them to Loki for storage and querying. In this section, we will walk through the installation process of Promtail, which includes downloading the necessary files, setting up configuration, and creating a service to ensure Promtail runs continuously as a background service. Step 1: Download Promtail The first step is to download the Promtail binary from the official GitHub repository. You can find the latest release here. For example, to download version 3.1.2, you can execute the following command: wget https://github.com/grafana/loki/releases/download/v2.8.0/promtail-linux-amd64.zip Step 2: Extract and Move Promtail to a Suitable Location Once the file is downloaded, extract it and move the binary to a directory included in the system’s $PATH, such as /usr/local/bin/. unzip promtail-linux-amd64.zip mv promtail-linux-amd64 /usr/local/bin/promtail Next, grant execute permissions to the Promtail binary to allow it to run: chmod +x /usr/local/bin/promtail Step 3: Create Promtail Configuration File Promtail requires a configuration file that defines how logs will be collected, where they will be sent, and other parameters. Create the configuration directory and the file as follows: mkdir -p /etc/promtail vim /etc/promtail/promtail-config.yaml Below is a sample configuration file you can use, which specifies the Promtail server settings, position tracking, Loki client configuration, and the log scraping setup. server: http_listen_port: 9080 grpc_listen_port: 0 positions: filename: /tmp/positions.yaml clients: - url: http://192.168.18.58:3100/loki/api/v1/push batchsize: 1048576 batchwait: 2s scrape_configs: - job_name: your-application-name static_configs: - targets: - localhost labels: job: your-application-name __path__: /var/log/your-application-name/*log Step 4: Create Systemd Service File In order to ensure that Promtail starts automatically during system boot and runs as a background service, we need to create a systemd service file. vim /etc/systemd/system/promtail.service Add the following content to the file: [Unit] Description=Promtail - A log collection agent for Loki Documentation=https://grafana.com/docs/loki/latest/clients/promtail/ After=network.target [Service] ExecStart=/usr/local/bin/promtail -config.file=/etc/promtail/promtail-config.yaml Restart=on-failure User=delian Group=delian [Install] WantedBy=multi-user.target Step 5: Start and Enable Promtail Service After creating the systemd service file, reload the systemd manager to register the new service and start it. Additionally, enable it to start automatically at boot time. systemctl daemon-reload systemctl start promtail systemctl enable promtail systemctl status promtail The service will now run in the background, collecting and forwarding logs to Loki according to the specified configuration. Conclusion In this article, we have outlined the necessary steps to install and configure Promtail. By following these procedures, you will have a fully functional Promtail agent collecting logs and sending them to Loki, ready for real-time log monitoring.]]></summary></entry><entry><title type="html">Stability Monitor Alertmanager</title><link href="http://localhost:4000/blog/stability-monitor-alertmanager/" rel="alternate" type="text/html" title="Stability Monitor Alertmanager" /><published>2025-01-14T00:00:00+08:00</published><updated>2025-01-14T00:00:00+08:00</updated><id>http://localhost:4000/blog/stability-monitor-alertmanager</id><content type="html" xml:base="http://localhost:4000/blog/stability-monitor-alertmanager/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Alertmanager is a tool designed to handle alerts sent by Prometheus, providing features such as deduplication, grouping, and routing of alerts to various receivers like email, Slack, or custom webhooks. This article demonstrates the process of installing and configuring Alertmanager, ensuring it operates as a service, and integrating it with Prometheus to handle alert notifications effectively.</p>

<h3 id="step-1-download-alertmanager">Step 1: Download Alertmanager</h3>

<p>The first step is to download the Alertmanager binary from the official GitHub repository. You can download the latest release from <a href="https://github.com/prometheus/alertmanager/releases">Prometheus’s Alertmanager GitHub page</a>.</p>

<p>For example, to download version 0.24.0, run the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://github.com/prometheus/alertmanager/releases/download/v0.24.0/alertmanager-0.24.0-linux-amd64.tar.gz
</code></pre></div></div>

<h3 id="step-2-extract-and-move-alertmanager-to-a-suitable-location">Step 2: Extract and Move Alertmanager to a Suitable Location</h3>

<p>Once the file is downloaded, extract it and move the binary to a directory included in the system’s <code class="language-plaintext highlighter-rouge">$PATH</code> (e.g., <code class="language-plaintext highlighter-rouge">/usr/local/bin/</code>):</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">tar</span> <span class="nt">-xvzf</span> alertmanager-0.24.0-linux-amd64.tar.gz
<span class="nb">mv </span>alertmanager-0.24.0-linux-amd64/alertmanager /usr/local/bin/
</code></pre></div></div>

<p>Next, grant execute permissions to the Alertmanager binary:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod</span> +x /usr/local/bin/alertmanager
</code></pre></div></div>

<h3 id="step-3-create-alertmanager-configuration-file">Step 3: Create Alertmanager Configuration File</h3>

<p>Alertmanager requires a configuration file (<code class="language-plaintext highlighter-rouge">alertmanager.yml</code>) to define how it handles incoming alerts and how they should be routed to notification receivers.</p>

<p>Create the configuration directory and the file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> /etc/alertmanager
vim /etc/alertmanager/alertmanager.yml
</code></pre></div></div>

<p>Here is a sample configuration file to get started:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">global</span><span class="pi">:</span>
  <span class="na">resolve_timeout</span><span class="pi">:</span> <span class="s">5m</span>

<span class="na">route</span><span class="pi">:</span>
  <span class="na">group_by</span><span class="pi">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">alertname'</span><span class="pi">]</span>
  <span class="na">receiver</span><span class="pi">:</span> <span class="s1">'</span><span class="s">email-config'</span>

<span class="na">receivers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s1">'</span><span class="s">email-config'</span>
    <span class="na">email_configs</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">to</span><span class="pi">:</span> <span class="s1">'</span><span class="s">your-email@example.com'</span>
        <span class="na">from</span><span class="pi">:</span> <span class="s1">'</span><span class="s">alertmanager@example.com'</span>
        <span class="na">smarthost</span><span class="pi">:</span> <span class="s1">'</span><span class="s">smtp.example.com:587'</span>
        <span class="na">auth_username</span><span class="pi">:</span> <span class="s1">'</span><span class="s">your-username'</span>
        <span class="na">auth_password</span><span class="pi">:</span> <span class="s1">'</span><span class="s">your-password'</span>
        <span class="na">require_tls</span><span class="pi">:</span> <span class="no">true</span>

<span class="na">group_interval</span><span class="pi">:</span> <span class="s">5m</span>
</code></pre></div></div>

<p>This configuration sets up a route that groups alerts by their <code class="language-plaintext highlighter-rouge">alertname</code> and sends notifications via email. You can customize this for other notification types (e.g., Slack, PagerDuty, etc.).</p>

<h3 id="step-4-create-systemd-service-file">Step 4: Create Systemd Service File</h3>

<p>To ensure that Alertmanager starts automatically at system boot and runs as a background service, create a <code class="language-plaintext highlighter-rouge">systemd</code> service file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim /etc/systemd/system/alertmanager.service
</code></pre></div></div>

<p>Add the following content to the file:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[Unit]</span>
<span class="py">Description</span><span class="p">=</span><span class="s">Alertmanager - A tool to handle alerts sent by Prometheus</span>
<span class="py">Documentation</span><span class="p">=</span><span class="s">https://prometheus.io/docs/alerting/latest/alertmanager/</span>
<span class="py">After</span><span class="p">=</span><span class="s">network.target</span>

<span class="nn">[Service]</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/usr/local/bin/alertmanager --config.file=/etc/alertmanager/alertmanager.yml</span>
<span class="py">Restart</span><span class="p">=</span><span class="s">on-failure</span>
<span class="py">User</span><span class="p">=</span><span class="s">delian</span>
<span class="py">Group</span><span class="p">=</span><span class="s">delian</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</code></pre></div></div>

<h3 id="step-5-start-and-enable-alertmanager-service">Step 5: Start and Enable Alertmanager Service</h3>

<p>Once the service file is created, reload the <code class="language-plaintext highlighter-rouge">systemd</code> manager to register the new service and start it. Additionally, enable it to start automatically at boot time:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>systemctl daemon-reload
systemctl start alertmanager
systemctl <span class="nb">enable </span>alertmanager
systemctl status alertmanager
</code></pre></div></div>

<p>Alertmanager will now run in the background and handle alerts according to the configuration file.</p>

<h3 id="step-6-configuring-alerting-rules-in-prometheus">Step 6: Configuring Alerting Rules in Prometheus</h3>

<p>To trigger alerts, Prometheus requires alerting rules. These rules define the conditions under which an alert should be fired. Alerting rules can be defined in the <code class="language-plaintext highlighter-rouge">prometheus.yml</code> configuration file or in a separate rules file.</p>

<h4 id="step-61-define-alerting-rules-in-prometheus">Step 6.1: Define Alerting Rules in Prometheus</h4>

<p>Create a separate file for alerting rules (e.g., <code class="language-plaintext highlighter-rouge">alert.rules.yml</code>), or define the rules directly in <code class="language-plaintext highlighter-rouge">prometheus.yml</code>. Below is an example of an alert rules file:</p>

<p>Create a rules file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim /etc/prometheus/alert.rules.yml
</code></pre></div></div>

<p>Add the following alerting rules:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">groups</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">example-alerts</span>
  <span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">alert</span><span class="pi">:</span> <span class="s">HighCPUUsage</span>
    <span class="na">expr</span><span class="pi">:</span> <span class="s">avg(rate(cpu_usage_seconds_total{mode="user"}[5m])) by (instance) &gt; </span><span class="m">0.9</span>
    <span class="na">for</span><span class="pi">:</span> <span class="s">5m</span>
    <span class="na">labels</span><span class="pi">:</span>
      <span class="na">severity</span><span class="pi">:</span> <span class="s">critical</span>
    <span class="na">annotations</span><span class="pi">:</span>
      <span class="na">summary</span><span class="pi">:</span> <span class="s2">"</span><span class="s">High</span><span class="nv"> </span><span class="s">CPU</span><span class="nv"> </span><span class="s">usage</span><span class="nv"> </span><span class="s">on</span><span class="nv"> </span><span class="s">"</span>
      <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">CPU</span><span class="nv"> </span><span class="s">usage</span><span class="nv"> </span><span class="s">is</span><span class="nv"> </span><span class="s">above</span><span class="nv"> </span><span class="s">90%</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">the</span><span class="nv"> </span><span class="s">last</span><span class="nv"> </span><span class="s">5</span><span class="nv"> </span><span class="s">minutes</span><span class="nv"> </span><span class="s">on</span><span class="nv"> </span><span class="s">."</span>

  <span class="pi">-</span> <span class="na">alert</span><span class="pi">:</span> <span class="s">DiskSpaceLow</span>
    <span class="na">expr</span><span class="pi">:</span> <span class="s">(node_filesystem_free_bytes / node_filesystem_size_bytes) * 100 &lt; </span><span class="m">10</span>
    <span class="na">for</span><span class="pi">:</span> <span class="s">10m</span>
    <span class="na">labels</span><span class="pi">:</span>
      <span class="na">severity</span><span class="pi">:</span> <span class="s">warning</span>
    <span class="na">annotations</span><span class="pi">:</span>
      <span class="na">summary</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Low</span><span class="nv"> </span><span class="s">disk</span><span class="nv"> </span><span class="s">space</span><span class="nv"> </span><span class="s">on</span><span class="nv"> </span><span class="s">"</span>
      <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Disk</span><span class="nv"> </span><span class="s">space</span><span class="nv"> </span><span class="s">on</span><span class="nv">  </span><span class="s">is</span><span class="nv"> </span><span class="s">below</span><span class="nv"> </span><span class="s">10%."</span>
</code></pre></div></div>

<p>Update the <code class="language-plaintext highlighter-rouge">prometheus.yml</code> file to include the alert rules:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">rule_files</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">/etc/prometheus/alert.rules.yml</span>
</code></pre></div></div>

<h4 id="step-62-ensure-prometheus-sends-alerts-to-alertmanager">Step 6.2: Ensure Prometheus Sends Alerts to Alertmanager</h4>

<p>Make sure Prometheus is configured to send alerts to Alertmanager. Modify the <code class="language-plaintext highlighter-rouge">alerting</code> section in the <code class="language-plaintext highlighter-rouge">prometheus.yml</code> file:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">alerting</span><span class="pi">:</span>
  <span class="na">alertmanagers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">static_configs</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">targets</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s1">'</span><span class="s">localhost:9093'</span>
</code></pre></div></div>

<p>Reload Prometheus to apply the changes:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>systemctl reload prometheus
</code></pre></div></div>

<h3 id="step-7-testing-and-verifying-alerts">Step 7: Testing and Verifying Alerts</h3>

<p>After setting up the alerting rules, it’s important to test that the alerts are correctly triggered and routed.</p>

<ol>
  <li>
    <p><strong>Verify Alertmanager Receives Alerts</strong>: Visit the Alertmanager web interface (<code class="language-plaintext highlighter-rouge">http://&lt;alertmanager-ip&gt;:9093</code>) to check if alerts are being received and processed.</p>
  </li>
  <li>
    <p><strong>Test Alert Triggers</strong>: You can artificially trigger alert conditions (e.g., simulate high CPU usage) to test the rule.</p>
  </li>
  <li>
    <p><strong>Check Notification Receivers</strong>: Ensure that the notifications are sent to the configured receivers (e.g., email, Slack).</p>
  </li>
</ol>

<h2 id="conclusion">Conclusion</h2>

<p>In this article, we have walked through the installation and configuration of Alertmanager, as well as the setup of alerting rules in Prometheus. By following the outlined steps, you can ensure that your monitoring system is capable of detecting and notifying you about critical infrastructure issues, helping you to maintain operational reliability.</p>

<p>By configuring both Prometheus and Alertmanager, you set up a robust alerting mechanism, which will notify you in a timely manner about critical problems within your infrastructure.</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="monitor" /><category term="alertmanager" /><summary type="html"><![CDATA[Introduction Alertmanager is a tool designed to handle alerts sent by Prometheus, providing features such as deduplication, grouping, and routing of alerts to various receivers like email, Slack, or custom webhooks. This article demonstrates the process of installing and configuring Alertmanager, ensuring it operates as a service, and integrating it with Prometheus to handle alert notifications effectively. Step 1: Download Alertmanager The first step is to download the Alertmanager binary from the official GitHub repository. You can download the latest release from Prometheus’s Alertmanager GitHub page. For example, to download version 0.24.0, run the following command: wget https://github.com/prometheus/alertmanager/releases/download/v0.24.0/alertmanager-0.24.0-linux-amd64.tar.gz Step 2: Extract and Move Alertmanager to a Suitable Location Once the file is downloaded, extract it and move the binary to a directory included in the system’s $PATH (e.g., /usr/local/bin/): tar -xvzf alertmanager-0.24.0-linux-amd64.tar.gz mv alertmanager-0.24.0-linux-amd64/alertmanager /usr/local/bin/ Next, grant execute permissions to the Alertmanager binary: chmod +x /usr/local/bin/alertmanager Step 3: Create Alertmanager Configuration File Alertmanager requires a configuration file (alertmanager.yml) to define how it handles incoming alerts and how they should be routed to notification receivers. Create the configuration directory and the file: mkdir -p /etc/alertmanager vim /etc/alertmanager/alertmanager.yml Here is a sample configuration file to get started: global: resolve_timeout: 5m route: group_by: ['alertname'] receiver: 'email-config' receivers: - name: 'email-config' email_configs: - to: 'your-email@example.com' from: 'alertmanager@example.com' smarthost: 'smtp.example.com:587' auth_username: 'your-username' auth_password: 'your-password' require_tls: true group_interval: 5m This configuration sets up a route that groups alerts by their alertname and sends notifications via email. You can customize this for other notification types (e.g., Slack, PagerDuty, etc.). Step 4: Create Systemd Service File To ensure that Alertmanager starts automatically at system boot and runs as a background service, create a systemd service file: vim /etc/systemd/system/alertmanager.service Add the following content to the file: [Unit] Description=Alertmanager - A tool to handle alerts sent by Prometheus Documentation=https://prometheus.io/docs/alerting/latest/alertmanager/ After=network.target [Service] ExecStart=/usr/local/bin/alertmanager --config.file=/etc/alertmanager/alertmanager.yml Restart=on-failure User=delian Group=delian [Install] WantedBy=multi-user.target Step 5: Start and Enable Alertmanager Service Once the service file is created, reload the systemd manager to register the new service and start it. Additionally, enable it to start automatically at boot time: systemctl daemon-reload systemctl start alertmanager systemctl enable alertmanager systemctl status alertmanager Alertmanager will now run in the background and handle alerts according to the configuration file. Step 6: Configuring Alerting Rules in Prometheus To trigger alerts, Prometheus requires alerting rules. These rules define the conditions under which an alert should be fired. Alerting rules can be defined in the prometheus.yml configuration file or in a separate rules file. Step 6.1: Define Alerting Rules in Prometheus Create a separate file for alerting rules (e.g., alert.rules.yml), or define the rules directly in prometheus.yml. Below is an example of an alert rules file: Create a rules file: vim /etc/prometheus/alert.rules.yml Add the following alerting rules: groups: - name: example-alerts rules: - alert: HighCPUUsage expr: avg(rate(cpu_usage_seconds_total{mode="user"}[5m])) by (instance) &gt; 0.9 for: 5m labels: severity: critical annotations: summary: "High CPU usage on " description: "CPU usage is above 90% for the last 5 minutes on ." - alert: DiskSpaceLow expr: (node_filesystem_free_bytes / node_filesystem_size_bytes) * 100 &lt; 10 for: 10m labels: severity: warning annotations: summary: "Low disk space on " description: "Disk space on is below 10%." Update the prometheus.yml file to include the alert rules: rule_files: - /etc/prometheus/alert.rules.yml Step 6.2: Ensure Prometheus Sends Alerts to Alertmanager Make sure Prometheus is configured to send alerts to Alertmanager. Modify the alerting section in the prometheus.yml file: alerting: alertmanagers: - static_configs: - targets: - 'localhost:9093' Reload Prometheus to apply the changes: systemctl reload prometheus Step 7: Testing and Verifying Alerts After setting up the alerting rules, it’s important to test that the alerts are correctly triggered and routed. Verify Alertmanager Receives Alerts: Visit the Alertmanager web interface (http://&lt;alertmanager-ip&gt;:9093) to check if alerts are being received and processed. Test Alert Triggers: You can artificially trigger alert conditions (e.g., simulate high CPU usage) to test the rule. Check Notification Receivers: Ensure that the notifications are sent to the configured receivers (e.g., email, Slack). Conclusion In this article, we have walked through the installation and configuration of Alertmanager, as well as the setup of alerting rules in Prometheus. By following the outlined steps, you can ensure that your monitoring system is capable of detecting and notifying you about critical infrastructure issues, helping you to maintain operational reliability. By configuring both Prometheus and Alertmanager, you set up a robust alerting mechanism, which will notify you in a timely manner about critical problems within your infrastructure.]]></summary></entry><entry><title type="html">Stability Monitor Jaeger</title><link href="http://localhost:4000/blog/stability-monitor-jaeger/" rel="alternate" type="text/html" title="Stability Monitor Jaeger" /><published>2025-01-11T00:00:00+08:00</published><updated>2025-01-11T00:00:00+08:00</updated><id>http://localhost:4000/blog/stability-monitor-jaeger</id><content type="html" xml:base="http://localhost:4000/blog/stability-monitor-jaeger/"><![CDATA[<h2 id="install-jaeger">Install Jaeger</h2>

<p>To install <strong>Jaeger</strong> version <strong>1.42.0</strong> on a Linux system, follow the steps below. Jaeger is an open-source distributed tracing system, and you can install it using pre-built binaries, Docker, or through package managers. This guide will cover the installation process using pre-built binaries.</p>

<h3 id="step-1-download-the-jaeger-binary">Step 1: Download the Jaeger Binary</h3>

<p>Go to the <a href="https://github.com/jaegertracing/jaeger/releases">Jaeger GitHub releases page</a> and find version <strong>1.42.0</strong>. Or use <code class="language-plaintext highlighter-rouge">wget</code> to directly download the binary:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://github.com/jaegertracing/jaeger/releases/download/v1.42.0/jaeger-linux-amd64.tar.gz
</code></pre></div></div>

<p>Once downloaded, extract the <code class="language-plaintext highlighter-rouge">.tar.gz</code> file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">tar</span> <span class="nt">-xvzf</span> jaeger-linux-amd64.tar.gz
</code></pre></div></div>

<p>This will create a folder containing the Jaeger binaries (<code class="language-plaintext highlighter-rouge">jaeger-agent</code>, <code class="language-plaintext highlighter-rouge">jaeger-collector</code>, <code class="language-plaintext highlighter-rouge">jaeger-query</code>, etc.).</p>

<h3 id="step-2-move-jaeger-to-a-system-directory">Step 2: Move Jaeger to a System Directory</h3>

<p>Move the extracted binaries to a directory in your PATH (e.g., <code class="language-plaintext highlighter-rouge">/usr/local/bin</code>):</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mv </span>jaeger-linux-amd64 /usr/local/bin/jaeger
</code></pre></div></div>

<p>Ensure the binaries are executable:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod</span> +x /usr/local/bin/jaeger
</code></pre></div></div>

<h3 id="step-3-create-a-configuration-file-optional">Step 3: Create a Configuration File (Optional)</h3>

<p>Create a directory for Jaeger configuration and add the <code class="language-plaintext highlighter-rouge">jaeger-config.yaml</code> file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> /etc/jaeger
vim /etc/jaeger/jaeger-config.yaml
</code></pre></div></div>

<p>The content for <code class="language-plaintext highlighter-rouge">jaeger-config.yaml</code>:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">collector</span><span class="pi">:</span>
  <span class="na">http-port</span><span class="pi">:</span> <span class="m">5775</span>
  <span class="na">grpc-port</span><span class="pi">:</span> <span class="m">14250</span>

<span class="na">agent</span><span class="pi">:</span>
  <span class="na">http-port</span><span class="pi">:</span> <span class="m">5778</span>

<span class="na">query</span><span class="pi">:</span>
  <span class="na">http-port</span><span class="pi">:</span> <span class="m">16686</span>

<span class="na">storage</span><span class="pi">:</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">cassandra</span>
  <span class="na">cassandra</span><span class="pi">:</span>
    <span class="na">contact-points</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">localhost:9042"</span>
    <span class="na">keyspace</span><span class="pi">:</span> <span class="s">jaeger</span>
    <span class="na">timeout</span><span class="pi">:</span> <span class="s">30s</span>
</code></pre></div></div>

<h3 id="step-4-configure-data-directories">Step 4: Configure Data Directories</h3>

<p>Define storage directories for Jaeger:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> /var/jaeger/cassandra /var/jaeger/storage
<span class="nb">chown</span> <span class="nt">-R</span> jaeger:jaeger /var/jaeger
</code></pre></div></div>

<p>Create the Jaeger systemd service file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim /etc/systemd/system/jaeger.service
</code></pre></div></div>

<p>Add the following content:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[Unit]</span>
<span class="py">Description</span><span class="p">=</span><span class="s">Jaeger</span>
<span class="py">Documentation</span><span class="p">=</span><span class="s">https://www.jaegertracing.io/docs/latest/</span>
<span class="py">After</span><span class="p">=</span><span class="s">network.target</span>

<span class="nn">[Service]</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/usr/local/bin/jaeger --config.file=/etc/jaeger/jaeger-config.yaml</span>
<span class="py">Restart</span><span class="p">=</span><span class="s">on-failure</span>
<span class="py">User</span><span class="p">=</span><span class="s">delian</span>
<span class="py">Group</span><span class="p">=</span><span class="s">delian</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</code></pre></div></div>

<h3 id="step-5-start-jaeger-service">Step 5: Start Jaeger Service</h3>

<p>Reload systemd, enable and start the Jaeger service:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>systemctl daemon-reload
systemctl <span class="nb">enable </span>jaeger
systemctl start jaeger
systemctl status jaeger
</code></pre></div></div>

<p>To monitor logs:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>journalctl <span class="nt">-u</span> jaeger <span class="nt">-f</span>
</code></pre></div></div>

<p>Verify the Jaeger version:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>jaeger <span class="nt">--version</span>
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>By following the above steps, you should have Jaeger installed and running with the necessary configurations for distributed tracing. You can now proceed to integrate Jaeger with other components like Prometheus, Grafana, etc., for a complete monitoring and tracing solution.</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="monitor" /><category term="tracing" /><summary type="html"><![CDATA[Install Jaeger To install Jaeger version 1.42.0 on a Linux system, follow the steps below. Jaeger is an open-source distributed tracing system, and you can install it using pre-built binaries, Docker, or through package managers. This guide will cover the installation process using pre-built binaries. Step 1: Download the Jaeger Binary Go to the Jaeger GitHub releases page and find version 1.42.0. Or use wget to directly download the binary: wget https://github.com/jaegertracing/jaeger/releases/download/v1.42.0/jaeger-linux-amd64.tar.gz Once downloaded, extract the .tar.gz file: tar -xvzf jaeger-linux-amd64.tar.gz This will create a folder containing the Jaeger binaries (jaeger-agent, jaeger-collector, jaeger-query, etc.). Step 2: Move Jaeger to a System Directory Move the extracted binaries to a directory in your PATH (e.g., /usr/local/bin): mv jaeger-linux-amd64 /usr/local/bin/jaeger Ensure the binaries are executable: chmod +x /usr/local/bin/jaeger Step 3: Create a Configuration File (Optional) Create a directory for Jaeger configuration and add the jaeger-config.yaml file: mkdir -p /etc/jaeger vim /etc/jaeger/jaeger-config.yaml The content for jaeger-config.yaml: collector: http-port: 5775 grpc-port: 14250 agent: http-port: 5778 query: http-port: 16686 storage: type: cassandra cassandra: contact-points: - "localhost:9042" keyspace: jaeger timeout: 30s Step 4: Configure Data Directories Define storage directories for Jaeger: mkdir -p /var/jaeger/cassandra /var/jaeger/storage chown -R jaeger:jaeger /var/jaeger Create the Jaeger systemd service file: vim /etc/systemd/system/jaeger.service Add the following content: [Unit] Description=Jaeger Documentation=https://www.jaegertracing.io/docs/latest/ After=network.target [Service] ExecStart=/usr/local/bin/jaeger --config.file=/etc/jaeger/jaeger-config.yaml Restart=on-failure User=delian Group=delian [Install] WantedBy=multi-user.target Step 5: Start Jaeger Service Reload systemd, enable and start the Jaeger service: systemctl daemon-reload systemctl enable jaeger systemctl start jaeger systemctl status jaeger To monitor logs: journalctl -u jaeger -f Verify the Jaeger version: jaeger --version Conclusion By following the above steps, you should have Jaeger installed and running with the necessary configurations for distributed tracing. You can now proceed to integrate Jaeger with other components like Prometheus, Grafana, etc., for a complete monitoring and tracing solution.]]></summary></entry><entry><title type="html">Stability Monitor Prometheus</title><link href="http://localhost:4000/blog/stability-monitor-prometheus/" rel="alternate" type="text/html" title="Stability Monitor Prometheus" /><published>2025-01-11T00:00:00+08:00</published><updated>2025-01-11T00:00:00+08:00</updated><id>http://localhost:4000/blog/stability-monitor-prometheus</id><content type="html" xml:base="http://localhost:4000/blog/stability-monitor-prometheus/"><![CDATA[<h2 id="background">Background</h2>
<p>A significant part of system stability is supported by monitoring. Large companies usually have well-established monitoring and operations teams to build the monitoring infrastructure. From a layered perspective, monitoring generally includes the following aspects:</p>
<table>
  <thead>
    <tr>
      <th>Monitoring Dimension</th>
      <th>Middleware Selection</th>
      <th>Reason for Selection</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Metric Monitoring</td>
      <td>Prometheus + Grafana</td>
      <td>Supports multiple Exporters, rich ecosystem, easy to configure alerts and visualizations</td>
    </tr>
    <tr>
      <td>Log Monitoring</td>
      <td>Loki + Promtail/Fluent Bit</td>
      <td>Lightweight log aggregation solution, seamlessly integrates with Grafana</td>
    </tr>
    <tr>
      <td>Distributed Tracing</td>
      <td>OpenTelemetry + Jaeger</td>
      <td>Open standard for distributed tracing, supports multiple languages</td>
    </tr>
    <tr>
      <td>Database Monitoring</td>
      <td>Exporter (e.g., MySQL Exporter)</td>
      <td>Prometheus maintained by official or community, supports mainstream databases</td>
    </tr>
    <tr>
      <td>Network Monitoring</td>
      <td>Blackbox Exporter</td>
      <td>Supports multi-protocol health checks like HTTP, TCP</td>
    </tr>
    <tr>
      <td>Alerting and Notification</td>
      <td>Alertmanager</td>
      <td>Supports multi-channel notifications (email, Slack, Webhook, SMS, etc.)</td>
    </tr>
  </tbody>
</table>

<h2 id="best-practices-for-selection">Best Practices for Selection</h2>
<p>Small and medium-sized companies can quickly build a monitoring system that suits their business characteristics. Prometheus has already become the standard for real-time monitoring. We can quickly set up our own monitoring system based on Prometheus:</p>
<table>
  <thead>
    <tr>
      <th>Monitoring Dimension</th>
      <th>Middleware Selection</th>
      <th>Reason for Selection</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Metric Monitoring</td>
      <td>Prometheus + Grafana</td>
      <td>Supports multiple Exporters, rich ecosystem, easy to configure alerts and visualizations</td>
    </tr>
    <tr>
      <td>Log Monitoring</td>
      <td>Loki + Promtail/Fluent Bit</td>
      <td>Lightweight log aggregation solution, seamlessly integrates with Grafana</td>
    </tr>
    <tr>
      <td>Distributed Tracing</td>
      <td>OpenTelemetry + Jaeger</td>
      <td>Open standard for distributed tracing, supports multiple languages</td>
    </tr>
    <tr>
      <td>Database Monitoring</td>
      <td>Exporter (e.g., MySQL Exporter, Redis Exporter)</td>
      <td>Prometheus maintained by official or community, supports mainstream databases</td>
    </tr>
    <tr>
      <td>Network Monitoring</td>
      <td>Blackbox Exporter</td>
      <td>Supports multi-protocol health checks like HTTP, TCP</td>
    </tr>
    <tr>
      <td>Alerting and Notification</td>
      <td>Alertmanager</td>
      <td>Supports multi-channel notifications (email, Slack, Webhook, SMS, etc.)</td>
    </tr>
  </tbody>
</table>

<h2 id="system-architecture-design">System Architecture Design</h2>
<div class="mermaid">
  graph TD;
    A[Prometheus] --&gt; B[Exporters]
    A --&gt; C[Blackbox Exporter]
    A --&gt; D[Alertmanager]
    B --&gt; E[Grafana]
    C --&gt; E
    D --&gt; E
    F[Loki] --&gt; G[Promtail/Fluent Bit]
    G --&gt; E
    H[OpenTelemetry] --&gt; I[Jaeger]
    I --&gt; E
</div>

<h2 id="defining-refined-monitoring-metrics">Defining Refined Monitoring Metrics</h2>
<h3 id="jvm-monitoring">JVM Monitoring</h3>

<p>JVM monitoring is used to track important JVM metrics, including GC (Garbage Collection) instant metrics, heap memory metrics, non-heap memory metrics, metaspace metrics, direct buffer metrics, JVM thread count, etc. This section introduces JVM monitoring and how to view JVM monitoring metrics.</p>

<p>JVM monitoring can track the following metrics:</p>

<ul>
  <li>GC (Garbage Collection) instant and cumulative details
    <ul>
      <li>FullGC count</li>
      <li>YoungGC count</li>
      <li>FullGC duration</li>
      <li>YoungGC duration</li>
    </ul>
  </li>
  <li>Heap Memory Details
    <ul>
      <li>Total heap memory</li>
      <li>Old generation heap memory size</li>
      <li>Young generation Survivor area size</li>
      <li>Young generation Eden area size</li>
    </ul>
  </li>
  <li>
    <p>Metaspace</p>

    <p>Metaspace size</p>
  </li>
  <li>Non-Heap Memory
    <ul>
      <li>Maximum non-heap memory size</li>
      <li>Used non-heap memory size</li>
    </ul>
  </li>
  <li>Direct Buffer
    <ul>
      <li>Total DirectBuffer size (bytes)</li>
      <li>Used DirectBuffer size (bytes)</li>
    </ul>
  </li>
  <li>JVM Thread Count
    <ul>
      <li>Total number of threads</li>
      <li>Number of deadlocked threads</li>
      <li>Number of newly created threads</li>
      <li>Number of blocked threads</li>
      <li>Number of runnable threads</li>
      <li>Number of terminated threads</li>
      <li>Number of threads in timed wait</li>
      <li>Number of threads in waiting state</li>
    </ul>
  </li>
</ul>

<div class="mermaid">
mindmap
  root((Java Process Memory Usage))
    JVM Memory
      Heap Memory
        Young Generation
        Old Generation
      Non-Heap Memory
        Metaspace
        Compressed Class Space
        Virtual Machine Thread Stack
        Native Thread Stack
        Code Cache
        Direct Buffers
    Non-JVM Memory
      Native Runtime Libraries
      JNI Native Code
</div>

<h3 id="host-monitoring">Host Monitoring</h3>

<p>Host monitoring tracks various metrics such as CPU, memory, disk, load, network traffic, and network packet metrics. This section introduces host monitoring and how to view host monitoring metrics.</p>

<p>Host monitoring can track the following metrics:</p>

<ul>
  <li>CPU
    <ul>
      <li>Total CPU usage</li>
      <li>System CPU usage</li>
      <li>User CPU usage</li>
      <li>CPU usage waiting for I/O completion</li>
    </ul>
  </li>
  <li>Physical Memory
    <ul>
      <li>Total system memory</li>
      <li>Free system memory</li>
      <li>Used system memory</li>
      <li>Memory in PageCache</li>
      <li>Memory in BufferCache</li>
    </ul>
  </li>
  <li>Disk
    <ul>
      <li>Total system disk size</li>
      <li>Free system disk size</li>
      <li>Used system disk size</li>
    </ul>
  </li>
  <li>
    <p>Load</p>

    <p>System load average</p>
  </li>
  <li>Network Traffic
    <ul>
      <li>Network received bytes</li>
      <li>Network sent bytes</li>
    </ul>
  </li>
  <li>Network Packets
    <ul>
      <li>Number of received packets per minute</li>
      <li>Number of sent packets per minute</li>
      <li>Number of network errors per minute</li>
      <li>Number of dropped packets per minute</li>
    </ul>
  </li>
</ul>

<h3 id="sql-call-analysis"><strong>SQL Call Analysis</strong></h3>

<p>View SQL call analysis to understand SQL call patterns in applications.</p>

<h3 id="error-code-monitoring">Error Code Monitoring</h3>

<p>For core business systems, such as payment systems, error code monitoring is essential.</p>

<p>Here’s how to install Prometheus step by step in English. If you use the docker you can use this to setup, this is the easy way. <a href="https://github.com/maddenmanel/springboot-prometheus-grafana">springboot-promethenus-grafana</a>.</p>

<h3 id="install-article-list">Install Article list</h3>

<ul>
  <li><a href="/tool/stability-monitor-loki/">Install Loki with Prometheus</a></li>
  <li><a href="/tool/stability-monitor-promtail/">Install Promtail with Prometheus</a></li>
</ul>

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: true });
</script>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="monitor" /><category term="stability" /><summary type="html"><![CDATA[Background A significant part of system stability is supported by monitoring. Large companies usually have well-established monitoring and operations teams to build the monitoring infrastructure. From a layered perspective, monitoring generally includes the following aspects: Monitoring Dimension Middleware Selection Reason for Selection Metric Monitoring Prometheus + Grafana Supports multiple Exporters, rich ecosystem, easy to configure alerts and visualizations Log Monitoring Loki + Promtail/Fluent Bit Lightweight log aggregation solution, seamlessly integrates with Grafana Distributed Tracing OpenTelemetry + Jaeger Open standard for distributed tracing, supports multiple languages Database Monitoring Exporter (e.g., MySQL Exporter) Prometheus maintained by official or community, supports mainstream databases Network Monitoring Blackbox Exporter Supports multi-protocol health checks like HTTP, TCP Alerting and Notification Alertmanager Supports multi-channel notifications (email, Slack, Webhook, SMS, etc.) Best Practices for Selection Small and medium-sized companies can quickly build a monitoring system that suits their business characteristics. Prometheus has already become the standard for real-time monitoring. We can quickly set up our own monitoring system based on Prometheus: Monitoring Dimension Middleware Selection Reason for Selection Metric Monitoring Prometheus + Grafana Supports multiple Exporters, rich ecosystem, easy to configure alerts and visualizations Log Monitoring Loki + Promtail/Fluent Bit Lightweight log aggregation solution, seamlessly integrates with Grafana Distributed Tracing OpenTelemetry + Jaeger Open standard for distributed tracing, supports multiple languages Database Monitoring Exporter (e.g., MySQL Exporter, Redis Exporter) Prometheus maintained by official or community, supports mainstream databases Network Monitoring Blackbox Exporter Supports multi-protocol health checks like HTTP, TCP Alerting and Notification Alertmanager Supports multi-channel notifications (email, Slack, Webhook, SMS, etc.) System Architecture Design graph TD; A[Prometheus] --&gt; B[Exporters] A --&gt; C[Blackbox Exporter] A --&gt; D[Alertmanager] B --&gt; E[Grafana] C --&gt; E D --&gt; E F[Loki] --&gt; G[Promtail/Fluent Bit] G --&gt; E H[OpenTelemetry] --&gt; I[Jaeger] I --&gt; E Defining Refined Monitoring Metrics JVM Monitoring JVM monitoring is used to track important JVM metrics, including GC (Garbage Collection) instant metrics, heap memory metrics, non-heap memory metrics, metaspace metrics, direct buffer metrics, JVM thread count, etc. This section introduces JVM monitoring and how to view JVM monitoring metrics. JVM monitoring can track the following metrics: GC (Garbage Collection) instant and cumulative details FullGC count YoungGC count FullGC duration YoungGC duration Heap Memory Details Total heap memory Old generation heap memory size Young generation Survivor area size Young generation Eden area size Metaspace Metaspace size Non-Heap Memory Maximum non-heap memory size Used non-heap memory size Direct Buffer Total DirectBuffer size (bytes) Used DirectBuffer size (bytes) JVM Thread Count Total number of threads Number of deadlocked threads Number of newly created threads Number of blocked threads Number of runnable threads Number of terminated threads Number of threads in timed wait Number of threads in waiting state mindmap root((Java Process Memory Usage)) JVM Memory Heap Memory Young Generation Old Generation Non-Heap Memory Metaspace Compressed Class Space Virtual Machine Thread Stack Native Thread Stack Code Cache Direct Buffers Non-JVM Memory Native Runtime Libraries JNI Native Code Host Monitoring Host monitoring tracks various metrics such as CPU, memory, disk, load, network traffic, and network packet metrics. This section introduces host monitoring and how to view host monitoring metrics. Host monitoring can track the following metrics: CPU Total CPU usage System CPU usage User CPU usage CPU usage waiting for I/O completion Physical Memory Total system memory Free system memory Used system memory Memory in PageCache Memory in BufferCache Disk Total system disk size Free system disk size Used system disk size Load System load average Network Traffic Network received bytes Network sent bytes Network Packets Number of received packets per minute Number of sent packets per minute Number of network errors per minute Number of dropped packets per minute SQL Call Analysis View SQL call analysis to understand SQL call patterns in applications. Error Code Monitoring For core business systems, such as payment systems, error code monitoring is essential. Here’s how to install Prometheus step by step in English. If you use the docker you can use this to setup, this is the easy way. springboot-promethenus-grafana. Install Article list Install Loki with Prometheus Install Promtail with Prometheus]]></summary></entry><entry><title type="html">Stability Monitor Loki</title><link href="http://localhost:4000/blog/stability-monitor-loki/" rel="alternate" type="text/html" title="Stability Monitor Loki" /><published>2025-01-11T00:00:00+08:00</published><updated>2025-01-11T00:00:00+08:00</updated><id>http://localhost:4000/blog/stability-monitor-loki</id><content type="html" xml:base="http://localhost:4000/blog/stability-monitor-loki/"><![CDATA[<h2 id="install-loki">Install Loki</h2>

<p>To install <strong>Loki</strong> version <strong>3.1.2</strong> on a Linux system, follow the steps below. Loki is an open-source log aggregation system developed by Grafana Labs, and you can install it using either pre-built binaries, Docker, or through package managers. We’ll use pre-built binaries for this guide.</p>

<h3 id="step-1-download-the-loki-binary">Step 1: Download the Loki Binary</h3>

<p>Go to the <a href="https://github.com/grafana/loki/releases">Loki GitHub releases page</a> and find version <strong>3.1.2</strong>. Or use <code class="language-plaintext highlighter-rouge">wget</code> to directly download the binary:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://github.com/grafana/loki/releases/download/v3.1.2/loki-linux-amd64.zip
</code></pre></div></div>

<p>Once downloaded, extract the <code class="language-plaintext highlighter-rouge">.zip</code> file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unzip loki-linux-amd64.zip
</code></pre></div></div>

<p>This will create a folder containing the Loki binary (<code class="language-plaintext highlighter-rouge">loki-linux-amd64</code>).</p>

<h3 id="step-2-move-loki-to-a-system-directory">Step 2: Move Loki to a System Directory</h3>

<p>Move the extracted binary to a directory in your PATH (e.g., <code class="language-plaintext highlighter-rouge">/usr/local/bin</code>):</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mv </span>loki-linux-amd64 /usr/local/bin/loki
</code></pre></div></div>

<p>Ensure the binary is executable:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod</span> +x /usr/local/bin/loki
</code></pre></div></div>

<h3 id="step-3-create-a-configuration-file-optional">Step 3: Create a Configuration File (Optional)</h3>

<p>Create a directory for Loki configuration and add the <code class="language-plaintext highlighter-rouge">local-config.yaml</code> file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> /etc/loki
vim /etc/loki/local-config.yaml
</code></pre></div></div>

<p>The content for <code class="language-plaintext highlighter-rouge">local-config.yaml</code>:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">auth_enabled</span><span class="pi">:</span> <span class="no">false</span>

<span class="na">server</span><span class="pi">:</span>
  <span class="na">http_listen_port</span><span class="pi">:</span> <span class="m">3100</span>
  <span class="na">grpc_listen_port</span><span class="pi">:</span> <span class="m">9095</span>

<span class="na">common</span><span class="pi">:</span>
  <span class="na">path_prefix</span><span class="pi">:</span> <span class="s">/loki/data</span>  

<span class="na">storage_config</span><span class="pi">:</span>
  <span class="na">boltdb_shipper</span><span class="pi">:</span>
    <span class="na">active_index_directory</span><span class="pi">:</span> <span class="s">/loki/index</span>
    <span class="na">cache_location</span><span class="pi">:</span> <span class="s">/loki/cache</span>
    <span class="na">resync_interval</span><span class="pi">:</span> <span class="s">10m</span>
  <span class="na">filesystem</span><span class="pi">:</span>
    <span class="na">directory</span><span class="pi">:</span> <span class="s">/loki/chunks</span>

<span class="na">limits_config</span><span class="pi">:</span>
  <span class="na">retention_period</span><span class="pi">:</span> <span class="s">90d</span>
  <span class="na">allow_structured_metadata</span><span class="pi">:</span> <span class="no">false</span> 

<span class="na">schema_config</span><span class="pi">:</span>
  <span class="na">configs</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">from</span><span class="pi">:</span> <span class="s">2020-10-21</span>
      <span class="na">store</span><span class="pi">:</span> <span class="s">boltdb-shipper</span>
      <span class="na">object_store</span><span class="pi">:</span> <span class="s">filesystem</span>
      <span class="na">schema</span><span class="pi">:</span> <span class="s">v13</span>
      <span class="na">index</span><span class="pi">:</span>
        <span class="na">prefix</span><span class="pi">:</span> <span class="s">index_</span>
        <span class="na">period</span><span class="pi">:</span> <span class="s">24h</span>  

<span class="na">compactor</span><span class="pi">:</span>
  <span class="na">working_directory</span><span class="pi">:</span> <span class="s">/loki/compactor</span> 

<span class="na">table_manager</span><span class="pi">:</span>
  <span class="na">retention_deletes_enabled</span><span class="pi">:</span> <span class="no">true</span>
  <span class="na">retention_period</span><span class="pi">:</span> <span class="s">90d</span>

<span class="na">ingester</span><span class="pi">:</span>
  <span class="na">lifecycler</span><span class="pi">:</span>
    <span class="na">ring</span><span class="pi">:</span>
      <span class="na">kvstore</span><span class="pi">:</span>
        <span class="na">store</span><span class="pi">:</span> <span class="s">memberlist</span>
      <span class="na">replication_factor</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">chunk_target_size</span><span class="pi">:</span> <span class="s">1048576</span>  
  <span class="na">max_chunk_age</span><span class="pi">:</span> <span class="s">1h</span> 

<span class="na">memberlist</span><span class="pi">:</span>
  <span class="na">join_members</span><span class="pi">:</span> <span class="pi">[]</span> 
</code></pre></div></div>

<h3 id="step-4-configure-log-file-storage">Step 4: Configure Log File Storage</h3>

<p>Define storage directories for Loki logs:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> /var/loki/chunks /var/loki/index /var/loki/cache /var/loki/compactor
<span class="nb">chown</span> <span class="nt">-R</span> loki:loki /var/loki
</code></pre></div></div>

<p>Create the Loki systemd service file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim /etc/systemd/system/loki.service
</code></pre></div></div>

<p>Add the following content:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[Unit]</span>
<span class="py">Description</span><span class="p">=</span><span class="s">Loki</span>
<span class="py">Documentation</span><span class="p">=</span><span class="s">https://grafana.com/docs/loki/latest/</span>
<span class="py">After</span><span class="p">=</span><span class="s">network.target</span>

<span class="nn">[Service]</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/usr/local/bin/loki -config.file=/etc/loki/local-config.yaml</span>
<span class="py">Restart</span><span class="p">=</span><span class="s">on-failure</span>
<span class="py">User</span><span class="p">=</span><span class="s">delian</span>
<span class="py">Group</span><span class="p">=</span><span class="s">delian</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</code></pre></div></div>

<h3 id="step-5-start-loki-service">Step 5: Start Loki Service</h3>

<p>Reload systemd, enable and start the Loki service:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>systemctl daemon-reload
systemctl <span class="nb">enable </span>loki
systemctl start loki
systemctl status loki
</code></pre></div></div>

<p>To monitor logs:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>journalctl <span class="nt">-u</span> loki <span class="nt">-f</span>
</code></pre></div></div>

<p>Verify the Loki version:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>loki <span class="nt">--version</span>
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>By following the above steps, you should have Loki installed and running with the necessary configurations for log aggregation. You can now proceed to integrate Loki with other components like Promtail, Grafana, etc., for a complete logging solution.</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="monitor" /><category term="stability" /><summary type="html"><![CDATA[Install Loki To install Loki version 3.1.2 on a Linux system, follow the steps below. Loki is an open-source log aggregation system developed by Grafana Labs, and you can install it using either pre-built binaries, Docker, or through package managers. We’ll use pre-built binaries for this guide. Step 1: Download the Loki Binary Go to the Loki GitHub releases page and find version 3.1.2. Or use wget to directly download the binary: wget https://github.com/grafana/loki/releases/download/v3.1.2/loki-linux-amd64.zip Once downloaded, extract the .zip file: unzip loki-linux-amd64.zip This will create a folder containing the Loki binary (loki-linux-amd64). Step 2: Move Loki to a System Directory Move the extracted binary to a directory in your PATH (e.g., /usr/local/bin): mv loki-linux-amd64 /usr/local/bin/loki Ensure the binary is executable: chmod +x /usr/local/bin/loki Step 3: Create a Configuration File (Optional) Create a directory for Loki configuration and add the local-config.yaml file: mkdir -p /etc/loki vim /etc/loki/local-config.yaml The content for local-config.yaml: auth_enabled: false server: http_listen_port: 3100 grpc_listen_port: 9095 common: path_prefix: /loki/data storage_config: boltdb_shipper: active_index_directory: /loki/index cache_location: /loki/cache resync_interval: 10m filesystem: directory: /loki/chunks limits_config: retention_period: 90d allow_structured_metadata: false schema_config: configs: - from: 2020-10-21 store: boltdb-shipper object_store: filesystem schema: v13 index: prefix: index_ period: 24h compactor: working_directory: /loki/compactor table_manager: retention_deletes_enabled: true retention_period: 90d ingester: lifecycler: ring: kvstore: store: memberlist replication_factor: 1 chunk_target_size: 1048576 max_chunk_age: 1h memberlist: join_members: [] Step 4: Configure Log File Storage Define storage directories for Loki logs: mkdir -p /var/loki/chunks /var/loki/index /var/loki/cache /var/loki/compactor chown -R loki:loki /var/loki Create the Loki systemd service file: vim /etc/systemd/system/loki.service Add the following content: [Unit] Description=Loki Documentation=https://grafana.com/docs/loki/latest/ After=network.target [Service] ExecStart=/usr/local/bin/loki -config.file=/etc/loki/local-config.yaml Restart=on-failure User=delian Group=delian [Install] WantedBy=multi-user.target Step 5: Start Loki Service Reload systemd, enable and start the Loki service: systemctl daemon-reload systemctl enable loki systemctl start loki systemctl status loki To monitor logs: journalctl -u loki -f Verify the Loki version: loki --version Conclusion By following the above steps, you should have Loki installed and running with the necessary configurations for log aggregation. You can now proceed to integrate Loki with other components like Promtail, Grafana, etc., for a complete logging solution.]]></summary></entry><entry><title type="html">Distribute Design Kafka</title><link href="http://localhost:4000/blog/distribute-design-kafka/" rel="alternate" type="text/html" title="Distribute Design Kafka" /><published>2018-07-11T00:00:00+08:00</published><updated>2018-07-11T00:00:00+08:00</updated><id>http://localhost:4000/blog/distribute-design-kafka</id><content type="html" xml:base="http://localhost:4000/blog/distribute-design-kafka/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Apache Kafka, initially developed by LinkedIn, is a distributed messaging system that has become a core component of Apache’s ecosystem. Written in Scala, Kafka is renowned for its scalability and high throughput. It is widely used in big data platforms and integrates seamlessly with distributed processing systems like Cloudera, Apache Storm, and Apache Spark.</p>

<p>As a commercially viable middleware, Kafka’s message reliability is of utmost importance. How can we ensure the precise transmission, accurate storage, and correct consumption of messages? This article dives into Kafka’s architecture and reliability mechanisms, including its storage structure, replication, and synchronization principles.</p>

<h2 id="key-terminologies">Key Terminologies</h2>

<table>
  <thead>
    <tr>
      <th>Term</th>
      <th>Explanation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Broker</td>
      <td>A Kafka node that handles message processing. Multiple brokers form a Kafka cluster.</td>
    </tr>
    <tr>
      <td>Topic</td>
      <td>Kafka uses topics to categorize messages. Every message published to Kafka needs a topic.</td>
    </tr>
    <tr>
      <td>Producer</td>
      <td>The client that sends messages to Kafka brokers.</td>
    </tr>
    <tr>
      <td>Consumer</td>
      <td>The client that reads messages from Kafka brokers.</td>
    </tr>
    <tr>
      <td>Consumer Group</td>
      <td>A group of consumers, where each message can only be consumed by one consumer within the group.</td>
    </tr>
    <tr>
      <td>Partition</td>
      <td>The physical division of a topic. A topic can have multiple partitions.</td>
    </tr>
    <tr>
      <td>Segment</td>
      <td>A partition is divided into multiple segments.</td>
    </tr>
    <tr>
      <td>Offset</td>
      <td>A unique identifier for messages within a partition. Each message has a sequential offset number.</td>
    </tr>
  </tbody>
</table>

<h2 id="kafkas-storage-mechanism">Kafka’s Storage Mechanism</h2>

<p>Kafka’s storage mechanism can be understood from four aspects:</p>

<h3 id="partition-distribution-in-topics">Partition Distribution in Topics</h3>

<p>In a Kafka cluster, each partition of a topic is stored across multiple brokers.<br />
For instance, consider a setup where a topic like report_push has four partitions.<br />
Kafka partitions are stored as directories with the naming convention: <code class="language-plaintext highlighter-rouge">topic-name-partition-index</code>.</p>

<h3 id="partition-file-storage">Partition File Storage</h3>

<p>Each partition is stored as a series of segments, which are essentially large files.<br />
Each segment file consists of two parts: an index file (.index) and a data file (.log).</p>

<div class="mermaid">
graph TD
  A[Producer] --&gt;|Pushes data| B[Kafka Broker]
  B --&gt;|Distributes messages| C[Partition]
  C --&gt; D[Segment]
  D --&gt; E[Message]
</div>

<h3 id="segment-storage-structure">Segment Storage Structure</h3>

<p>A segment file includes index and data files. The index file stores metadata, while the data file stores actual messages.<br />
Segment files are named based on the last message’s offset, helping Kafka efficiently locate data.</p>

<div class="mermaid">
graph TD
  A[Segment] --&gt; B[Index File]
  A --&gt; C[Data File]
  B --&gt; D[Message Metadata]
  C --&gt; E[Message Data]
</div>

<h3 id="locating-messages-using-offsets">Locating Messages Using Offsets</h3>

<p>Kafka uses the offset to locate messages within the partition. Each message has an offset number, which is used to efficiently find and retrieve it.</p>

<div class="mermaid">
graph TD
  A[Partition] --&gt; B[Message with Offset]
  B --&gt; C[Index File Lookup]
  C --&gt; D[Data File Access]
</div>

<h2 id="kafkas-internal-architecture">Kafka’s Internal Architecture</h2>

<p>The internal architecture of Kafka includes the following core components:</p>

<ul>
  <li><strong>Producer:</strong> Sends messages to the Kafka cluster.</li>
  <li><strong>Broker:</strong> Handles messages and stores partitions.</li>
  <li><strong>Consumer:</strong> Pulls messages from the Kafka cluster.</li>
  <li><strong>Zookeeper:</strong> Manages Kafka’s cluster state and coordinates leader election and partition management.</li>
</ul>

<div class="mermaid">
graph TD
  A[Producer] --&gt; B[Broker]
  B --&gt; C[Partition]
  C --&gt; D[Consumer]
  D --&gt; E[Zookeeper]
</div>

<h2 id="ensuring-high-reliability">Ensuring High Reliability</h2>

<p>Kafka’s high reliability stems from its robust replication mechanism, which ensures message availability even in the event of broker failures.</p>

<h3 id="data-synchronization">Data Synchronization</h3>

<p>Kafka introduced replication in version 0.8 to mitigate data loss during broker failures. Each partition has multiple replicas, with one replica acting as the leader and others as followers.</p>

<div class="mermaid">
graph TD
  A[Producer] --&gt; B[Leader Partition]
  B --&gt; C[Follower 1]
  B --&gt; D[Follower 2]
  C --&gt; E[Write Sync]
  D --&gt; E[Write Sync]
</div>

<h3 id="replica-placement-strategy">Replica Placement Strategy</h3>

<p>Kafka distributes replicas across multiple brokers to balance load. It employs a modular arithmetic approach to determine where to place replicas.</p>

<div class="mermaid">
graph TD
  A[Broker 1] --&gt; B[Partition 1 Replica 1]
  A[Broker 2] --&gt; C[Partition 1 Replica 2]
  A[Broker 3] --&gt; D[Partition 1 Replica 3]
</div>

<h3 id="synchronization-strategy">Synchronization Strategy</h3>

<p>Producers only send messages to the leader of a partition. After the leader writes the message, followers synchronize with the leader.</p>

<div class="mermaid">
graph TD
  A[Producer] --&gt; B[Leader]
  B --&gt; C[Follower 1]
  B --&gt; D[Follower 2]
  C --&gt; E[ACK]
  D --&gt; E[ACK]
  E --&gt; F[Leader Commit]
</div>

<h3 id="leader-election">Leader Election</h3>

<p>Kafka’s leader election is managed by Zookeeper, which uses a distributed lock mechanism to ensure that only one replica becomes the leader of a partition.</p>

<div class="mermaid">
graph TD
  A[Zookeeper] --&gt; B[Partition 1 Leader Election]
  B --&gt; C[Follower 1]
  B --&gt; D[Follower 2]
  C --&gt; E[Leader Role]
  D --&gt; F[Follower Role]
</div>

<h2 id="conclusion">Conclusion</h2>

<p>Kafka’s architecture ensures high reliability, scalability, and performance, making it a vital tool in modern data processing. With its sophisticated replication mechanism, partitioning strategies, and efficient storage system, Kafka delivers message guarantees and fault tolerance that are crucial in large-scale distributed systems.</p>

<p>The above content outlines Kafka’s design and operational principles, integrating your provided article with added explanations and visualization using Mermaid diagrams. This should give a clear and comprehensive understanding of Kafka’s message storage, architecture, and reliability features.</p>

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: true });
</script>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="distribute" /><category term="kafka" /><summary type="html"><![CDATA[Introduction Apache Kafka, initially developed by LinkedIn, is a distributed messaging system that has become a core component of Apache’s ecosystem. Written in Scala, Kafka is renowned for its scalability and high throughput. It is widely used in big data platforms and integrates seamlessly with distributed processing systems like Cloudera, Apache Storm, and Apache Spark. As a commercially viable middleware, Kafka’s message reliability is of utmost importance. How can we ensure the precise transmission, accurate storage, and correct consumption of messages? This article dives into Kafka’s architecture and reliability mechanisms, including its storage structure, replication, and synchronization principles. Key Terminologies Term Explanation Broker A Kafka node that handles message processing. Multiple brokers form a Kafka cluster. Topic Kafka uses topics to categorize messages. Every message published to Kafka needs a topic. Producer The client that sends messages to Kafka brokers. Consumer The client that reads messages from Kafka brokers. Consumer Group A group of consumers, where each message can only be consumed by one consumer within the group. Partition The physical division of a topic. A topic can have multiple partitions. Segment A partition is divided into multiple segments. Offset A unique identifier for messages within a partition. Each message has a sequential offset number. Kafka’s Storage Mechanism Kafka’s storage mechanism can be understood from four aspects: Partition Distribution in Topics In a Kafka cluster, each partition of a topic is stored across multiple brokers. For instance, consider a setup where a topic like report_push has four partitions. Kafka partitions are stored as directories with the naming convention: topic-name-partition-index. Partition File Storage Each partition is stored as a series of segments, which are essentially large files. Each segment file consists of two parts: an index file (.index) and a data file (.log). graph TD A[Producer] --&gt;|Pushes data| B[Kafka Broker] B --&gt;|Distributes messages| C[Partition] C --&gt; D[Segment] D --&gt; E[Message] Segment Storage Structure A segment file includes index and data files. The index file stores metadata, while the data file stores actual messages. Segment files are named based on the last message’s offset, helping Kafka efficiently locate data. graph TD A[Segment] --&gt; B[Index File] A --&gt; C[Data File] B --&gt; D[Message Metadata] C --&gt; E[Message Data] Locating Messages Using Offsets Kafka uses the offset to locate messages within the partition. Each message has an offset number, which is used to efficiently find and retrieve it. graph TD A[Partition] --&gt; B[Message with Offset] B --&gt; C[Index File Lookup] C --&gt; D[Data File Access] Kafka’s Internal Architecture The internal architecture of Kafka includes the following core components: Producer: Sends messages to the Kafka cluster. Broker: Handles messages and stores partitions. Consumer: Pulls messages from the Kafka cluster. Zookeeper: Manages Kafka’s cluster state and coordinates leader election and partition management. graph TD A[Producer] --&gt; B[Broker] B --&gt; C[Partition] C --&gt; D[Consumer] D --&gt; E[Zookeeper] Ensuring High Reliability Kafka’s high reliability stems from its robust replication mechanism, which ensures message availability even in the event of broker failures. Data Synchronization Kafka introduced replication in version 0.8 to mitigate data loss during broker failures. Each partition has multiple replicas, with one replica acting as the leader and others as followers. graph TD A[Producer] --&gt; B[Leader Partition] B --&gt; C[Follower 1] B --&gt; D[Follower 2] C --&gt; E[Write Sync] D --&gt; E[Write Sync] Replica Placement Strategy Kafka distributes replicas across multiple brokers to balance load. It employs a modular arithmetic approach to determine where to place replicas. graph TD A[Broker 1] --&gt; B[Partition 1 Replica 1] A[Broker 2] --&gt; C[Partition 1 Replica 2] A[Broker 3] --&gt; D[Partition 1 Replica 3] Synchronization Strategy Producers only send messages to the leader of a partition. After the leader writes the message, followers synchronize with the leader. graph TD A[Producer] --&gt; B[Leader] B --&gt; C[Follower 1] B --&gt; D[Follower 2] C --&gt; E[ACK] D --&gt; E[ACK] E --&gt; F[Leader Commit] Leader Election Kafka’s leader election is managed by Zookeeper, which uses a distributed lock mechanism to ensure that only one replica becomes the leader of a partition. graph TD A[Zookeeper] --&gt; B[Partition 1 Leader Election] B --&gt; C[Follower 1] B --&gt; D[Follower 2] C --&gt; E[Leader Role] D --&gt; F[Follower Role] Conclusion Kafka’s architecture ensures high reliability, scalability, and performance, making it a vital tool in modern data processing. With its sophisticated replication mechanism, partitioning strategies, and efficient storage system, Kafka delivers message guarantees and fault tolerance that are crucial in large-scale distributed systems. The above content outlines Kafka’s design and operational principles, integrating your provided article with added explanations and visualization using Mermaid diagrams. This should give a clear and comprehensive understanding of Kafka’s message storage, architecture, and reliability features.]]></summary></entry><entry><title type="html">Distribute Design Redis</title><link href="http://localhost:4000/blog/distribute-design-redis/" rel="alternate" type="text/html" title="Distribute Design Redis" /><published>2018-07-11T00:00:00+08:00</published><updated>2025-01-24T05:20:02+08:00</updated><id>http://localhost:4000/blog/distribute-design-redis</id><content type="html" xml:base="http://localhost:4000/blog/distribute-design-redis/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Redis, originally developed by Salvatore Sanfilippo, is an open-source, in-memory key-value store known for its speed, versatility, and high availability. It is widely used for caching, real-time analytics, pub/sub messaging, and as a NoSQL database in distributed systems.</p>

<p>This article explores Redis’s internal architecture, its approach to data persistence and replication, as well as various deployment architectures and best practices. Additionally, we will discuss Redis’s performance optimization for handling hot data and its ideal use cases in large-scale distributed systems.</p>

<h2 id="key-terminologies">Key Terminologies</h2>

<table>
  <thead>
    <tr>
      <th>Term</th>
      <th>Explanation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Node</td>
      <td>A Redis instance in a Redis cluster or standalone setup.</td>
    </tr>
    <tr>
      <td>Key-Value Store</td>
      <td>Redis stores data in a key-value format, where each key maps to a value.</td>
    </tr>
    <tr>
      <td>Publisher</td>
      <td>A client that sends messages to a Redis channel.</td>
    </tr>
    <tr>
      <td>Subscriber</td>
      <td>A client that listens to messages from a Redis channel.</td>
    </tr>
    <tr>
      <td>Replication</td>
      <td>Redis replication allows data to be copied to multiple nodes for fault tolerance.</td>
    </tr>
    <tr>
      <td>Master Node</td>
      <td>The primary node in a replication setup, responsible for data writes.</td>
    </tr>
    <tr>
      <td>Replica Node</td>
      <td>A secondary node in a replication setup that copies data from the master node.</td>
    </tr>
    <tr>
      <td>Persistence</td>
      <td>Redis offers different persistence options, such as snapshots and append-only files (AOF).</td>
    </tr>
  </tbody>
</table>

<h2 id="redis-storage-mechanism">Redis Storage Mechanism</h2>

<p>Redis’s design is optimized for high performance by storing data in memory, but it also supports persistence to ensure data durability. Redis provides several options for data persistence and replication to ensure that data remains safe even during node failures.</p>

<h3 id="key-value-store-model">Key-Value Store Model</h3>

<p>Redis stores all data as key-value pairs. This simple model is highly efficient for quick lookups, making Redis ideal for caching and real-time systems.</p>

<h3 id="data-persistence-in-redis">Data Persistence in Redis</h3>

<p>Redis provides two primary persistence mechanisms to ensure durability:</p>

<ul>
  <li>
    <p><strong>Snapshotting (RDB):</strong> Redis periodically saves the dataset to disk in the form of snapshots (RDB files). This allows quick restarts but may lead to data loss if the server crashes between snapshots.</p>
  </li>
  <li>
    <p><strong>Append-Only File (AOF):</strong> Redis logs every write operation received by the server to an append-only file. This ensures that even if Redis crashes, it can recover the exact state from the logs, albeit at a performance cost.</p>
  </li>
</ul>

<h3 id="redis-data-structures">Redis Data Structures</h3>

<p>Redis supports a wide range of data types, including:</p>

<ul>
  <li><strong>Strings:</strong> Simple key-value pairs (e.g., session data).</li>
  <li><strong>Lists:</strong> Ordered collections of strings, ideal for queues or message buffers.</li>
  <li><strong>Sets:</strong> Unordered collections of unique strings, useful for tasks like membership checking.</li>
  <li><strong>Hashes:</strong> A map of field-value pairs, akin to a dictionary.</li>
  <li><strong>Sorted Sets:</strong> Like sets, but with an associated score, allowing ordering by score (used for leaderboards, etc.).</li>
</ul>

<h3 id="memory-management">Memory Management</h3>

<p>Redis employs an <strong>in-memory</strong> storage model, meaning all data is held in RAM. While this provides extreme performance benefits, it also limits the amount of data that can be handled. Redis handles memory pressure through eviction policies, such as:</p>

<ul>
  <li><strong>LRU (Least Recently Used):</strong> Evicts the least recently accessed keys when the memory limit is reached.</li>
  <li><strong>TTL (Time To Live):</strong> Keys can have an expiration time, and Redis will automatically remove expired keys.</li>
  <li><strong>No-eviction:</strong> When memory is full, Redis returns errors for write operations.</li>
</ul>

<h2 id="redis-internal-architecture">Redis Internal Architecture</h2>

<p>Redis’s internal architecture can be broken down into key components that ensure high availability, reliability, and scalability:</p>

<h3 id="master-slave-replication">Master-Slave Replication</h3>

<p>Redis uses a master-slave replication model to ensure data redundancy. The master node is responsible for handling all write operations, while the slave nodes asynchronously replicate data from the master. This replication ensures that data is always available, even if the master node fails.</p>

<div class="mermaid">
graph TD
  A[Publisher] --&gt; B[Redis Master Node]
  B --&gt; C[Replica 1]
  B --&gt; D[Replica 2]
  C --&gt; E[Write Sync]
  D --&gt; E[Write Sync]
</div>

<h3 id="redis-sentinel-for-high-availability">Redis Sentinel for High Availability</h3>

<p>Redis Sentinel provides high availability and automatic failover. It monitors the health of Redis instances, and if the master node fails, Sentinel will automatically promote one of the replica nodes to become the new master.</p>

<div class="mermaid">
graph TD
  A[Sentinel] --&gt; B[Master Node]
  B --&gt; C[Replica 1]
  B --&gt; D[Replica 2]
  C --&gt; E[Failover Process]
  D --&gt; E[Failover Process]
</div>

<h3 id="redis-cluster-for-horizontal-scaling">Redis Cluster for Horizontal Scaling</h3>

<p>Redis Cluster is a distributed implementation of Redis that partitions data across multiple nodes. Each node in the cluster holds a portion of the data and can act as a master or replica. This allows Redis to scale horizontally by adding more nodes to handle increased load and larger datasets.</p>

<div class="mermaid">
graph TD
  A[Redis Client] --&gt; B[Cluster Node 1]
  B --&gt; C[Cluster Node 2]
  C --&gt; D[Cluster Node 3]
  D --&gt; E[Cluster Node N]
</div>

<h2 id="handling-hot-data">Handling Hot Data</h2>

<p>Hot data refers to frequently accessed data that must be served with minimal latency. Redis excels at managing hot data due to its in-memory design and support for complex data structures.</p>

<h3 id="techniques-for-optimizing-hot-data-access">Techniques for Optimizing Hot Data Access</h3>

<ol>
  <li><strong>Data Sharding:</strong> Redis Cluster allows data to be partitioned (sharded) across multiple nodes, ensuring that hot data resides on the appropriate node with minimal impact on performance.</li>
  <li><strong>Caching:</strong> Redis is widely used as a cache for frequently accessed data. By caching hot data in Redis, applications can reduce the load on primary databases and improve response times.</li>
  <li><strong>Memory Optimizations:</strong> Using data types like hashes, which store multiple fields in a single key, can reduce memory usage when dealing with large datasets with frequent access patterns.</li>
</ol>

<h2 id="deployment-architectures">Deployment Architectures</h2>

<p>Redis offers three primary deployment architectures to suit different operational needs:</p>

<h3 id="1-standalone-redis-instance">1. <strong>Standalone Redis Instance</strong></h3>

<p>A simple, single Redis instance is suitable for small-scale applications or as a local cache for a single application. However, this architecture doesn’t provide fault tolerance or horizontal scaling.</p>

<h3 id="2-master-slave-replication">2. <strong>Master-Slave Replication</strong></h3>

<p>In this architecture, a Redis master node is paired with one or more replica nodes. The master handles all write operations, while the replicas asynchronously copy the data. This architecture offers redundancy, allowing reads to be distributed among replicas.</p>

<h3 id="3-redis-cluster">3. <strong>Redis Cluster</strong></h3>

<p>Redis Cluster is a more advanced architecture where data is partitioned across multiple Redis nodes, allowing horizontal scaling. Redis Cluster automatically distributes data and handles failover, making it suitable for large-scale distributed applications.</p>

<h2 id="use-cases-for-redis">Use Cases for Redis</h2>

<p>Redis is suitable for various use cases due to its high performance and flexibility:</p>

<ol>
  <li><strong>Caching:</strong> Redis is commonly used as a cache for web applications to store frequently accessed data, reducing load on databases and improving response times.</li>
  <li><strong>Session Management:</strong> Redis can store session data for web applications, ensuring quick access to user-specific information.</li>
  <li><strong>Real-Time Analytics:</strong> Redis’s support for data structures like sorted sets makes it ideal for real-time analytics and tracking use cases (e.g., leaderboards).</li>
  <li><strong>Pub/Sub Messaging:</strong> Redis’s Pub/Sub capabilities are widely used for building real-time messaging systems and event-driven architectures.</li>
</ol>

<h2 id="best-practices-for-redis">Best Practices for Redis</h2>

<ol>
  <li><strong>Persistence Options:</strong> Choose the appropriate persistence model based on your use case. If durability is crucial, use AOF for better recovery options. If performance is more important, use RDB snapshots.</li>
  <li><strong>Memory Management:</strong> Monitor memory usage and set proper eviction policies (LRU, TTL) to ensure Redis doesn’t run out of memory.</li>
  <li><strong>Sharding and Clustering:</strong> Use Redis Cluster to distribute large datasets across multiple nodes for scalability and high availability.</li>
  <li><strong>Monitoring and Alerts:</strong> Implement monitoring tools like Redis’s <code class="language-plaintext highlighter-rouge">INFO</code> command or third-party tools to keep track of Redis’s performance metrics (e.g., memory usage, commands per second).</li>
  <li><strong>Security:</strong> Use password protection and encrypted connections (e.g., TLS) to secure Redis instances, especially in production environments.</li>
</ol>

<h2 id="conclusion">Conclusion</h2>

<p>Redis is a powerful, fast, and flexible data store that can be used in various distributed systems. Its design focuses on simplicity and performance, with in-memory storage and sophisticated replication and clustering mechanisms to ensure reliability, scalability, and fault tolerance. By understanding Redis’s underlying architecture and following best practices, you can build highly efficient and resilient distributed systems.</p>

<p>Redis’s ability to handle hot data, combined with its flexible deployment architectures, makes it an excellent choice for caching, real-time analytics, messaging, and many other use cases.</p>

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: true });
</script>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="distribute" /><category term="redis" /><summary type="html"><![CDATA[Introduction Redis, originally developed by Salvatore Sanfilippo, is an open-source, in-memory key-value store known for its speed, versatility, and high availability. It is widely used for caching, real-time analytics, pub/sub messaging, and as a NoSQL database in distributed systems. This article explores Redis’s internal architecture, its approach to data persistence and replication, as well as various deployment architectures and best practices. Additionally, we will discuss Redis’s performance optimization for handling hot data and its ideal use cases in large-scale distributed systems. Key Terminologies Term Explanation Node A Redis instance in a Redis cluster or standalone setup. Key-Value Store Redis stores data in a key-value format, where each key maps to a value. Publisher A client that sends messages to a Redis channel. Subscriber A client that listens to messages from a Redis channel. Replication Redis replication allows data to be copied to multiple nodes for fault tolerance. Master Node The primary node in a replication setup, responsible for data writes. Replica Node A secondary node in a replication setup that copies data from the master node. Persistence Redis offers different persistence options, such as snapshots and append-only files (AOF). Redis Storage Mechanism Redis’s design is optimized for high performance by storing data in memory, but it also supports persistence to ensure data durability. Redis provides several options for data persistence and replication to ensure that data remains safe even during node failures. Key-Value Store Model Redis stores all data as key-value pairs. This simple model is highly efficient for quick lookups, making Redis ideal for caching and real-time systems. Data Persistence in Redis Redis provides two primary persistence mechanisms to ensure durability: Snapshotting (RDB): Redis periodically saves the dataset to disk in the form of snapshots (RDB files). This allows quick restarts but may lead to data loss if the server crashes between snapshots. Append-Only File (AOF): Redis logs every write operation received by the server to an append-only file. This ensures that even if Redis crashes, it can recover the exact state from the logs, albeit at a performance cost. Redis Data Structures Redis supports a wide range of data types, including: Strings: Simple key-value pairs (e.g., session data). Lists: Ordered collections of strings, ideal for queues or message buffers. Sets: Unordered collections of unique strings, useful for tasks like membership checking. Hashes: A map of field-value pairs, akin to a dictionary. Sorted Sets: Like sets, but with an associated score, allowing ordering by score (used for leaderboards, etc.). Memory Management Redis employs an in-memory storage model, meaning all data is held in RAM. While this provides extreme performance benefits, it also limits the amount of data that can be handled. Redis handles memory pressure through eviction policies, such as: LRU (Least Recently Used): Evicts the least recently accessed keys when the memory limit is reached. TTL (Time To Live): Keys can have an expiration time, and Redis will automatically remove expired keys. No-eviction: When memory is full, Redis returns errors for write operations. Redis Internal Architecture Redis’s internal architecture can be broken down into key components that ensure high availability, reliability, and scalability: Master-Slave Replication Redis uses a master-slave replication model to ensure data redundancy. The master node is responsible for handling all write operations, while the slave nodes asynchronously replicate data from the master. This replication ensures that data is always available, even if the master node fails. graph TD A[Publisher] --&gt; B[Redis Master Node] B --&gt; C[Replica 1] B --&gt; D[Replica 2] C --&gt; E[Write Sync] D --&gt; E[Write Sync] Redis Sentinel for High Availability Redis Sentinel provides high availability and automatic failover. It monitors the health of Redis instances, and if the master node fails, Sentinel will automatically promote one of the replica nodes to become the new master. graph TD A[Sentinel] --&gt; B[Master Node] B --&gt; C[Replica 1] B --&gt; D[Replica 2] C --&gt; E[Failover Process] D --&gt; E[Failover Process] Redis Cluster for Horizontal Scaling Redis Cluster is a distributed implementation of Redis that partitions data across multiple nodes. Each node in the cluster holds a portion of the data and can act as a master or replica. This allows Redis to scale horizontally by adding more nodes to handle increased load and larger datasets. graph TD A[Redis Client] --&gt; B[Cluster Node 1] B --&gt; C[Cluster Node 2] C --&gt; D[Cluster Node 3] D --&gt; E[Cluster Node N] Handling Hot Data Hot data refers to frequently accessed data that must be served with minimal latency. Redis excels at managing hot data due to its in-memory design and support for complex data structures. Techniques for Optimizing Hot Data Access Data Sharding: Redis Cluster allows data to be partitioned (sharded) across multiple nodes, ensuring that hot data resides on the appropriate node with minimal impact on performance. Caching: Redis is widely used as a cache for frequently accessed data. By caching hot data in Redis, applications can reduce the load on primary databases and improve response times. Memory Optimizations: Using data types like hashes, which store multiple fields in a single key, can reduce memory usage when dealing with large datasets with frequent access patterns. Deployment Architectures Redis offers three primary deployment architectures to suit different operational needs: 1. Standalone Redis Instance A simple, single Redis instance is suitable for small-scale applications or as a local cache for a single application. However, this architecture doesn’t provide fault tolerance or horizontal scaling. 2. Master-Slave Replication In this architecture, a Redis master node is paired with one or more replica nodes. The master handles all write operations, while the replicas asynchronously copy the data. This architecture offers redundancy, allowing reads to be distributed among replicas. 3. Redis Cluster Redis Cluster is a more advanced architecture where data is partitioned across multiple Redis nodes, allowing horizontal scaling. Redis Cluster automatically distributes data and handles failover, making it suitable for large-scale distributed applications. Use Cases for Redis Redis is suitable for various use cases due to its high performance and flexibility: Caching: Redis is commonly used as a cache for web applications to store frequently accessed data, reducing load on databases and improving response times. Session Management: Redis can store session data for web applications, ensuring quick access to user-specific information. Real-Time Analytics: Redis’s support for data structures like sorted sets makes it ideal for real-time analytics and tracking use cases (e.g., leaderboards). Pub/Sub Messaging: Redis’s Pub/Sub capabilities are widely used for building real-time messaging systems and event-driven architectures. Best Practices for Redis Persistence Options: Choose the appropriate persistence model based on your use case. If durability is crucial, use AOF for better recovery options. If performance is more important, use RDB snapshots. Memory Management: Monitor memory usage and set proper eviction policies (LRU, TTL) to ensure Redis doesn’t run out of memory. Sharding and Clustering: Use Redis Cluster to distribute large datasets across multiple nodes for scalability and high availability. Monitoring and Alerts: Implement monitoring tools like Redis’s INFO command or third-party tools to keep track of Redis’s performance metrics (e.g., memory usage, commands per second). Security: Use password protection and encrypted connections (e.g., TLS) to secure Redis instances, especially in production environments. Conclusion Redis is a powerful, fast, and flexible data store that can be used in various distributed systems. Its design focuses on simplicity and performance, with in-memory storage and sophisticated replication and clustering mechanisms to ensure reliability, scalability, and fault tolerance. By understanding Redis’s underlying architecture and following best practices, you can build highly efficient and resilient distributed systems. Redis’s ability to handle hot data, combined with its flexible deployment architectures, makes it an excellent choice for caching, real-time analytics, messaging, and many other use cases.]]></summary></entry><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/blog/welcome-to-jekyll/" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2010-04-19T03:34:30+08:00</published><updated>2010-04-19T03:34:30+08:00</updated><id>http://localhost:4000/blog/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/blog/welcome-to-jekyll/"><![CDATA[<p>You’ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>To add new posts, simply add a file in the <code class="language-plaintext highlighter-rouge">_posts</code> directory that follows the convention <code class="language-plaintext highlighter-rouge">YYYY-MM-DD-name-of-post.ext</code> and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span>
</code></pre></div></div>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll’s GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="Jekyll" /><summary type="html"><![CDATA[You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.]]></summary></entry></feed>